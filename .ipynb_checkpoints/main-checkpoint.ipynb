{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules import EncoderNet,DecoderNet,DiscriminatorNet_reconstruction,GeneratorNet\n",
    "from network import transformNet\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "#import resnet\n",
    "#import invresnet\n",
    "from dataload import load_data ,batchfy \n",
    "from torchsummary import summary\n",
    "import torch\n",
    "from torch import nn,optim\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import time\n",
    "from torchvision import transforms, utils\n",
    "TIMEOUT=300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.set_default_tensor_type(torch.cuda.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Encoder=torch.load(\"Encoder_64batch.h\")\n",
    "Decoder=torch.load(\"Decoder_64batch.h\")\n",
    "#Encoder=resnet.resnet18()\n",
    "#Encoder=Encoder.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_load,test_load=batchfy(batch_size=100)\n",
    "show_img=iter(train_load)\n",
    "for batch_i, (real_images, gender,glasses) in enumerate(train_load):\n",
    "    debug=real_images[0]\n",
    "    plt.imshow((debug.numpy().transpose((1, 2, 0))*0.5)+0.5)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "phi(\n",
       "  (fc1): Linear(in_features=99, out_features=1000, bias=True)\n",
       "  (fc2): Linear(in_features=1000, out_features=99, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phi=transformNet.phi()\n",
    "phi.to(device)\n",
    "\n",
    "invphi=transformNet.phi(inv=True)\n",
    "invphi.to(device)\n",
    "\n",
    "#Transform=transformNet.full_phi(phi,invphi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_phi = optim.Adam(phi.parameters(), lr=0.0001, betas=(0.9, 0.999))\n",
    "opt_invphi = optim.Adam(invphi.parameters(), lr=0.001, betas=(0.9, 0.999))\n",
    "#criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "params = [phi.parameters(), invphi.parameters()]\n",
    "\n",
    "opt_transform=optim.Adam(itertools.chain(*params),lr=0.001,betas=(0.9,0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TripleletLoss(batch,targetAttribute):\n",
    "    def triplet(value, positive, negative, margin=0.2) : \n",
    "        d = nn.PairwiseDistance(p=2)\n",
    "        distance = d(value, positive) - d(value, negative) + margin \n",
    "        loss = torch.mean(torch.max(distance, torch.zeros_like(distance))) \n",
    "        return loss\n",
    "    \n",
    "    def findtriplet(src,attribute):\n",
    "        timeout_start = time.time()\n",
    "        index_list=np.arange(len(attribute)).tolist()\n",
    "        rand=random.sample(index_list,len(attribute))\n",
    "        for i,posindex in enumerate(rand):\n",
    "            if attribute[src]==attribute[posindex]:\n",
    "                if src != posindex:\n",
    "                        break      \n",
    "            if i==len(attribute)-1:\n",
    "                posindex=src            \n",
    "        rand=random.sample(index_list,len(attribute))                \n",
    "        for i,negindex in enumerate(rand):\n",
    "            if(attribute[src] !=attribute[negindex]):\n",
    "                break   \n",
    "            if i==len(attribute)-1:\n",
    "                negindex=src\n",
    "                \n",
    "        return posindex,negindex\n",
    "    loss=0\n",
    "    pos_pair=None\n",
    "    for i,value in enumerate(batch):\n",
    "        posindex,negindex=findtriplet(i,targetAttribute)\n",
    "\n",
    "        if not i:\n",
    "\n",
    "            pos_pair=batch[posindex].unsqueeze(0)\n",
    "            neg_pair=batch[negindex].unsqueeze(0)\n",
    "        else:\n",
    "            pos_pair=torch.cat((pos_pair,batch[posindex].unsqueeze(0)),0)\n",
    "            neg_pair=torch.cat((neg_pair,batch[negindex].unsqueeze(0)),0)\n",
    "\n",
    "\n",
    "    return triplet(batch,pos_pair,neg_pair)\n",
    "\n",
    "def reconstruction_loss(z,z_tilde,optimizer):\n",
    "    loss = nn.L1Loss()\n",
    "    optimizer.zero_grad()\n",
    "    error_recons=loss(z,z_tilde)\n",
    "    error_recons.backward(retain_graph=True)\n",
    "    optimizer.step()\n",
    "    return error_recons\n",
    "\n",
    "def concat(z_list):\n",
    "    return torch.cat((z_list[0],z_list[1],z_list[2]),1)\n",
    "\n",
    "def cyclic_loss(z1,z2,z3,true_glasses,true_gender,opt_transform):\n",
    "    batch_size=z1.size(0)\n",
    "    swapped_pos=torch.randperm(batch_size)   \n",
    "    z1_hat = z1[swapped_pos]   #Permutation\n",
    "    true_glasses=true_glasses[swapped_pos]  \n",
    "    swapped_pos=torch.randperm(batch_size)\n",
    "    true_gender=true_glasses[swapped_pos]\n",
    "    z2_hat=z2[swapped_pos]\n",
    "    swapped_pos=torch.randperm(batch_size)\n",
    "    z3_hat=z3[swapped_pos]\n",
    "    true_gender=true_glasses[true_glasses]\n",
    "    z_aster=torch.cat((z1_hat,z2_hat,z3),1)\n",
    "    recontructed_z_aster=concat(phi(Encoder(Decoder(invphi(z_aster)))))\n",
    "    #Cycle_Consistency,Loss                 \n",
    "    opt_transform.zero_grad()\n",
    "    loss = nn.MSELoss()                                                     \n",
    "    consistency_loss = loss(z_aster,recontructed_z_aster)\n",
    "    consistency_loss.backward()\n",
    "    opt_transform.step()\n",
    "    \n",
    "    \n",
    "   # opt_transform.zero_grad()\n",
    "    #augmentation_loss =TripleletLoss(z1_hat,true_glasses)# + TripleletLoss(z2_hat,true_gender)\n",
    "    #print(augmentation_loss)\n",
    "  #  augmenstation_loss.backward()\n",
    "   # opt_transform.step()\n",
    "    return consistency_loss #+augmentation_loss       \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(Encoder,phi,invphi,train_load,num_epochs=40):\n",
    "    t_start = time.time()\n",
    "    Encoder.eval()\n",
    "    Decoder.eval()\n",
    "    phi.train()\n",
    "    invphi.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"Epoch:\", epoch)\n",
    "        for batch_i, (real_images, gender,glasses) in enumerate(train_load):\n",
    "            batch_size = real_images.size(0)\n",
    "            real_images=real_images.to(device,dtype=torch.float)\n",
    "            latent_vector=Encoder(real_images).detach()\n",
    "            glass_vector,gender_vector,remain=phi(latent_vector)\n",
    "            \n",
    "            #Reconstruction Loss\n",
    "            z_tilde=invphi(torch.cat((glass_vector,gender_vector,remain),1))\n",
    "            loss_reconstruction=reconstruction_loss(latent_vector,z_tilde,opt_transform)\n",
    "            \n",
    "            \n",
    "            #Task Loss\n",
    "            opt_phi.zero_grad()       \n",
    "            loss=TripleletLoss(glass_vector,glasses) +    TripleletLoss(gender_vector,gender)  \n",
    "            #print(loss)\n",
    "            loss.backward()\n",
    "            opt_phi.step()\n",
    "            \n",
    "            glass_vector=glass_vector.detach()\n",
    "            gender_vector=gender_vector.detach()\n",
    "            remain=remain.detach()\n",
    "\n",
    "            \n",
    "            #Cyclic Loss\n",
    "            loss_cycle=cyclic_loss(glass_vector,gender_vector,remain,glasses,gender,opt_transform)\n",
    "            \n",
    "            if (batch_i) % 300 == 0:\n",
    "                print(\"Batch: \", batch_i)\n",
    "                print(\"Task Loss: \", loss.item())\n",
    "                print(\"Reconstruction Loss: \",loss_reconstruction.item())\n",
    "                print(\"Cyclic Loss: \",loss_cycle.item())\n",
    "        t_end = time.time()\n",
    "        duration_avg = (t_end - t_start) / (epoch + 1.0)\n",
    "        print(\"Elapsed Time: \",duration_avg)\n",
    "        #torch.save(phi,'Phi.h')\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Batch:  0\n",
      "Task Loss:  0.647313117980957\n",
      "Reconstruction Loss:  0.13472586870193481\n",
      "Cyclic Loss:  0.025652391836047173\n",
      "Batch:  300\n",
      "Task Loss:  0.35863977670669556\n",
      "Reconstruction Loss:  0.03567996993660927\n",
      "Cyclic Loss:  0.008588036522269249\n",
      "Batch:  600\n",
      "Task Loss:  0.3992929458618164\n",
      "Reconstruction Loss:  0.03635320067405701\n",
      "Cyclic Loss:  0.008220270276069641\n",
      "Batch:  900\n",
      "Task Loss:  0.25084248185157776\n",
      "Reconstruction Loss:  0.03142152354121208\n",
      "Cyclic Loss:  0.007709841709583998\n",
      "Batch:  1200\n",
      "Task Loss:  0.2544933259487152\n",
      "Reconstruction Loss:  0.03300273045897484\n",
      "Cyclic Loss:  0.0076814149506390095\n",
      "Batch:  1500\n",
      "Task Loss:  0.17253053188323975\n",
      "Reconstruction Loss:  0.03056464157998562\n",
      "Cyclic Loss:  0.007671115919947624\n",
      "Elapsed Time:  521.5809080600739\n",
      "Epoch: 1\n",
      "Batch:  0\n",
      "Task Loss:  0.2644643485546112\n",
      "Reconstruction Loss:  0.030414987355470657\n",
      "Cyclic Loss:  0.007866722531616688\n",
      "Batch:  300\n",
      "Task Loss:  0.2279462218284607\n",
      "Reconstruction Loss:  0.02879204973578453\n",
      "Cyclic Loss:  0.007897392846643925\n",
      "Batch:  600\n",
      "Task Loss:  0.316147118806839\n",
      "Reconstruction Loss:  0.027378130704164505\n",
      "Cyclic Loss:  0.007808055728673935\n",
      "Batch:  900\n",
      "Task Loss:  0.23302067816257477\n",
      "Reconstruction Loss:  0.028705382719635963\n",
      "Cyclic Loss:  0.008078579790890217\n",
      "Batch:  1200\n",
      "Task Loss:  0.2759567201137543\n",
      "Reconstruction Loss:  0.032363954931497574\n",
      "Cyclic Loss:  0.008559172973036766\n",
      "Batch:  1500\n",
      "Task Loss:  0.19144554436206818\n",
      "Reconstruction Loss:  0.03531139716506004\n",
      "Cyclic Loss:  0.00976742897182703\n",
      "Elapsed Time:  522.7821142673492\n",
      "Epoch: 2\n",
      "Batch:  0\n",
      "Task Loss:  0.20052120089530945\n",
      "Reconstruction Loss:  0.033720120787620544\n",
      "Cyclic Loss:  0.009817089885473251\n",
      "Batch:  300\n",
      "Task Loss:  0.10708719491958618\n",
      "Reconstruction Loss:  0.034484777599573135\n",
      "Cyclic Loss:  0.010431456379592419\n",
      "Batch:  600\n",
      "Task Loss:  0.23793205618858337\n",
      "Reconstruction Loss:  0.030537724494934082\n",
      "Cyclic Loss:  0.010287604294717312\n",
      "Batch:  900\n",
      "Task Loss:  0.29780104756355286\n",
      "Reconstruction Loss:  0.027699502184987068\n",
      "Cyclic Loss:  0.011523895896971226\n",
      "Batch:  1200\n",
      "Task Loss:  0.28848493099212646\n",
      "Reconstruction Loss:  0.03216325119137764\n",
      "Cyclic Loss:  0.011673469096422195\n",
      "Batch:  1500\n",
      "Task Loss:  0.25130271911621094\n",
      "Reconstruction Loss:  0.036018967628479004\n",
      "Cyclic Loss:  0.01178837101906538\n",
      "Elapsed Time:  522.370483716329\n",
      "Epoch: 3\n",
      "Batch:  0\n",
      "Task Loss:  0.3229101598262787\n",
      "Reconstruction Loss:  0.03497150540351868\n",
      "Cyclic Loss:  0.013764038681983948\n",
      "Batch:  300\n",
      "Task Loss:  0.307125985622406\n",
      "Reconstruction Loss:  0.03981645405292511\n",
      "Cyclic Loss:  0.014928768388926983\n",
      "Batch:  600\n",
      "Task Loss:  0.24602094292640686\n",
      "Reconstruction Loss:  0.035636115819215775\n",
      "Cyclic Loss:  0.0157760102301836\n",
      "Batch:  900\n",
      "Task Loss:  0.37479135394096375\n",
      "Reconstruction Loss:  0.04147069901227951\n",
      "Cyclic Loss:  0.017874814569950104\n",
      "Batch:  1200\n",
      "Task Loss:  0.24186372756958008\n",
      "Reconstruction Loss:  0.03478124737739563\n",
      "Cyclic Loss:  0.01814526878297329\n",
      "Batch:  1500\n",
      "Task Loss:  0.2386649250984192\n",
      "Reconstruction Loss:  0.031684670597314835\n",
      "Cyclic Loss:  0.01723049394786358\n",
      "Elapsed Time:  522.0375204086304\n",
      "Epoch: 4\n",
      "Batch:  0\n",
      "Task Loss:  0.10642199218273163\n",
      "Reconstruction Loss:  0.03601084277033806\n",
      "Cyclic Loss:  0.0205235555768013\n",
      "Batch:  300\n",
      "Task Loss:  0.42621487379074097\n",
      "Reconstruction Loss:  0.036647383123636246\n",
      "Cyclic Loss:  0.021377306431531906\n",
      "Batch:  600\n",
      "Task Loss:  0.18030402064323425\n",
      "Reconstruction Loss:  0.032082442194223404\n",
      "Cyclic Loss:  0.020126067101955414\n",
      "Batch:  900\n",
      "Task Loss:  0.5710151791572571\n",
      "Reconstruction Loss:  1.299474835395813\n",
      "Cyclic Loss:  1.6529358625411987\n",
      "Batch:  1200\n",
      "Task Loss:  0.1763269156217575\n",
      "Reconstruction Loss:  0.019763505086302757\n",
      "Cyclic Loss:  0.014639658853411674\n",
      "Batch:  1500\n",
      "Task Loss:  0.18337056040763855\n",
      "Reconstruction Loss:  0.02770509198307991\n",
      "Cyclic Loss:  0.014582930132746696\n",
      "Elapsed Time:  522.151558971405\n",
      "Epoch: 5\n",
      "Batch:  0\n",
      "Task Loss:  0.38423532247543335\n",
      "Reconstruction Loss:  0.03115062415599823\n",
      "Cyclic Loss:  0.016223866492509842\n",
      "Batch:  300\n",
      "Task Loss:  0.368586927652359\n",
      "Reconstruction Loss:  0.03201264888048172\n",
      "Cyclic Loss:  0.017457706853747368\n",
      "Batch:  600\n",
      "Task Loss:  0.5021733045578003\n",
      "Reconstruction Loss:  0.03277602046728134\n",
      "Cyclic Loss:  0.018290670588612556\n",
      "Batch:  900\n",
      "Task Loss:  0.1604202389717102\n",
      "Reconstruction Loss:  0.032694775611162186\n",
      "Cyclic Loss:  0.0201523769646883\n",
      "Batch:  1200\n",
      "Task Loss:  0.309416800737381\n",
      "Reconstruction Loss:  0.03520318120718002\n",
      "Cyclic Loss:  0.022623972967267036\n",
      "Batch:  1500\n",
      "Task Loss:  0.321241170167923\n",
      "Reconstruction Loss:  0.033339474350214005\n",
      "Cyclic Loss:  0.021688837558031082\n",
      "Elapsed Time:  522.3987613519033\n",
      "Epoch: 6\n",
      "Batch:  0\n",
      "Task Loss:  0.18563508987426758\n",
      "Reconstruction Loss:  0.029061680659651756\n",
      "Cyclic Loss:  0.02206617407500744\n",
      "Batch:  300\n",
      "Task Loss:  0.2934621274471283\n",
      "Reconstruction Loss:  0.030568525195121765\n",
      "Cyclic Loss:  0.024136532098054886\n",
      "Batch:  600\n",
      "Task Loss:  0.3445620536804199\n",
      "Reconstruction Loss:  0.035597894340753555\n",
      "Cyclic Loss:  0.020454034209251404\n",
      "Batch:  900\n",
      "Task Loss:  0.2743906080722809\n",
      "Reconstruction Loss:  0.03201954811811447\n",
      "Cyclic Loss:  0.016013603657484055\n",
      "Batch:  1200\n",
      "Task Loss:  0.2779601812362671\n",
      "Reconstruction Loss:  0.030679121613502502\n",
      "Cyclic Loss:  0.017593909054994583\n",
      "Batch:  1500\n",
      "Task Loss:  0.18185091018676758\n",
      "Reconstruction Loss:  0.0368238128721714\n",
      "Cyclic Loss:  0.019432630389928818\n",
      "Elapsed Time:  522.5369910512652\n",
      "Epoch: 7\n",
      "Batch:  0\n",
      "Task Loss:  0.3650723695755005\n",
      "Reconstruction Loss:  0.03288329392671585\n",
      "Cyclic Loss:  0.021384065970778465\n",
      "Batch:  300\n",
      "Task Loss:  0.37277084589004517\n",
      "Reconstruction Loss:  0.029517503455281258\n",
      "Cyclic Loss:  0.023068973794579506\n",
      "Batch:  600\n",
      "Task Loss:  0.31064122915267944\n",
      "Reconstruction Loss:  0.030902255326509476\n",
      "Cyclic Loss:  0.02331351302564144\n",
      "Batch:  900\n",
      "Task Loss:  0.3429144024848938\n",
      "Reconstruction Loss:  0.033834926784038544\n",
      "Cyclic Loss:  0.025813717395067215\n",
      "Batch:  1200\n",
      "Task Loss:  0.3896770179271698\n",
      "Reconstruction Loss:  0.02447419799864292\n",
      "Cyclic Loss:  0.017229700461030006\n",
      "Batch:  1500\n",
      "Task Loss:  0.39210736751556396\n",
      "Reconstruction Loss:  0.032829247415065765\n",
      "Cyclic Loss:  0.01878557913005352\n",
      "Elapsed Time:  522.9173920452595\n",
      "Epoch: 8\n",
      "Batch:  0\n",
      "Task Loss:  0.43249210715293884\n",
      "Reconstruction Loss:  0.03491729497909546\n",
      "Cyclic Loss:  0.020466666668653488\n",
      "Batch:  300\n",
      "Task Loss:  0.2935493588447571\n",
      "Reconstruction Loss:  0.03255763649940491\n",
      "Cyclic Loss:  0.0229549091309309\n",
      "Batch:  600\n",
      "Task Loss:  0.29805198311805725\n",
      "Reconstruction Loss:  0.034488920122385025\n",
      "Cyclic Loss:  0.023202266544103622\n",
      "Batch:  900\n",
      "Task Loss:  0.1820419430732727\n",
      "Reconstruction Loss:  0.03671210631728172\n",
      "Cyclic Loss:  0.02833608351647854\n",
      "Batch:  1200\n",
      "Task Loss:  0.32919666171073914\n",
      "Reconstruction Loss:  0.03511587902903557\n",
      "Cyclic Loss:  0.028445018455386162\n",
      "Batch:  1500\n",
      "Task Loss:  0.34194415807724\n",
      "Reconstruction Loss:  0.02893208898603916\n",
      "Cyclic Loss:  0.019716039299964905\n",
      "Elapsed Time:  523.61930375629\n",
      "Epoch: 9\n",
      "Batch:  0\n",
      "Task Loss:  0.27478501200675964\n",
      "Reconstruction Loss:  0.021565955132246017\n",
      "Cyclic Loss:  0.015544815920293331\n",
      "Batch:  300\n",
      "Task Loss:  0.2899572253227234\n",
      "Reconstruction Loss:  0.04934386536478996\n",
      "Cyclic Loss:  0.020745137706398964\n",
      "Batch:  600\n",
      "Task Loss:  0.42499780654907227\n",
      "Reconstruction Loss:  0.044009122997522354\n",
      "Cyclic Loss:  0.0249289870262146\n",
      "Batch:  900\n",
      "Task Loss:  0.2425099015235901\n",
      "Reconstruction Loss:  0.03526754304766655\n",
      "Cyclic Loss:  0.023191696032881737\n",
      "Batch:  1200\n",
      "Task Loss:  0.6881170272827148\n",
      "Reconstruction Loss:  0.36587828397750854\n",
      "Cyclic Loss:  0.44776466488838196\n",
      "Batch:  1500\n",
      "Task Loss:  0.20037071406841278\n",
      "Reconstruction Loss:  0.026336636394262314\n",
      "Cyclic Loss:  0.01821480318903923\n",
      "Elapsed Time:  524.2091481924057\n",
      "Epoch: 10\n",
      "Batch:  0\n",
      "Task Loss:  0.282574325799942\n",
      "Reconstruction Loss:  0.02814040146768093\n",
      "Cyclic Loss:  0.01742825098335743\n",
      "Batch:  300\n",
      "Task Loss:  0.1867470145225525\n",
      "Reconstruction Loss:  0.03580470383167267\n",
      "Cyclic Loss:  0.022188324481248856\n",
      "Batch:  600\n",
      "Task Loss:  0.2642034590244293\n",
      "Reconstruction Loss:  0.02973136305809021\n",
      "Cyclic Loss:  0.02419535256922245\n",
      "Batch:  900\n",
      "Task Loss:  0.348966121673584\n",
      "Reconstruction Loss:  0.035433441400527954\n",
      "Cyclic Loss:  0.026901135221123695\n",
      "Batch:  1200\n",
      "Task Loss:  0.24130377173423767\n",
      "Reconstruction Loss:  0.035694420337677\n",
      "Cyclic Loss:  0.02985764481127262\n",
      "Batch:  1500\n",
      "Task Loss:  0.4088042378425598\n",
      "Reconstruction Loss:  0.04140327498316765\n",
      "Cyclic Loss:  0.021517155691981316\n",
      "Elapsed Time:  524.3880130594426\n",
      "Epoch: 11\n",
      "Batch:  0\n",
      "Task Loss:  0.3362787365913391\n",
      "Reconstruction Loss:  0.02789212018251419\n",
      "Cyclic Loss:  0.018450172618031502\n",
      "Batch:  300\n",
      "Task Loss:  0.3453560471534729\n",
      "Reconstruction Loss:  0.03229952231049538\n",
      "Cyclic Loss:  0.021096915006637573\n",
      "Batch:  600\n",
      "Task Loss:  0.285677969455719\n",
      "Reconstruction Loss:  0.03239639103412628\n",
      "Cyclic Loss:  0.021082082763314247\n",
      "Batch:  900\n",
      "Task Loss:  0.2801457643508911\n",
      "Reconstruction Loss:  0.035770583897829056\n",
      "Cyclic Loss:  0.024759579449892044\n",
      "Batch:  1200\n",
      "Task Loss:  0.1945405900478363\n",
      "Reconstruction Loss:  0.03930360823869705\n",
      "Cyclic Loss:  0.028177518397569656\n",
      "Batch:  1500\n",
      "Task Loss:  0.38561680912971497\n",
      "Reconstruction Loss:  0.0632782056927681\n",
      "Cyclic Loss:  0.0302641112357378\n",
      "Elapsed Time:  524.4157223701477\n",
      "Epoch: 12\n",
      "Batch:  0\n",
      "Task Loss:  0.31027668714523315\n",
      "Reconstruction Loss:  0.030232932418584824\n",
      "Cyclic Loss:  0.01955251209437847\n",
      "Batch:  300\n",
      "Task Loss:  0.3163263201713562\n",
      "Reconstruction Loss:  0.029100200161337852\n",
      "Cyclic Loss:  0.02126406505703926\n",
      "Batch:  600\n",
      "Task Loss:  0.2734423279762268\n",
      "Reconstruction Loss:  0.032636091113090515\n",
      "Cyclic Loss:  0.02390873432159424\n",
      "Batch:  900\n",
      "Task Loss:  0.22046969830989838\n",
      "Reconstruction Loss:  0.04298850893974304\n",
      "Cyclic Loss:  0.02946898341178894\n",
      "Batch:  1200\n",
      "Task Loss:  0.26900696754455566\n",
      "Reconstruction Loss:  0.13085375726222992\n",
      "Cyclic Loss:  0.14470990002155304\n",
      "Batch:  1500\n",
      "Task Loss:  0.22571824491024017\n",
      "Reconstruction Loss:  0.027400068938732147\n",
      "Cyclic Loss:  0.017000971361994743\n",
      "Elapsed Time:  524.2597678257869\n",
      "Epoch: 13\n",
      "Batch:  0\n",
      "Task Loss:  0.31738293170928955\n",
      "Reconstruction Loss:  0.02845088578760624\n",
      "Cyclic Loss:  0.017850885167717934\n",
      "Batch:  300\n",
      "Task Loss:  0.28447896242141724\n",
      "Reconstruction Loss:  0.031788744032382965\n",
      "Cyclic Loss:  0.018250586465001106\n",
      "Batch:  600\n",
      "Task Loss:  0.30952826142311096\n",
      "Reconstruction Loss:  0.02838282287120819\n",
      "Cyclic Loss:  0.020795036107301712\n",
      "Batch:  900\n",
      "Task Loss:  0.3433576226234436\n",
      "Reconstruction Loss:  0.028589637950062752\n",
      "Cyclic Loss:  0.022577160969376564\n",
      "Batch:  1200\n",
      "Task Loss:  0.26671817898750305\n",
      "Reconstruction Loss:  0.026149071753025055\n",
      "Cyclic Loss:  0.018524905666708946\n",
      "Batch:  1500\n",
      "Task Loss:  0.1980646550655365\n",
      "Reconstruction Loss:  0.030193408951163292\n",
      "Cyclic Loss:  0.018200349062681198\n",
      "Elapsed Time:  524.6625871998923\n",
      "Epoch: 14\n",
      "Batch:  0\n",
      "Task Loss:  0.3524775803089142\n",
      "Reconstruction Loss:  0.04069050773978233\n",
      "Cyclic Loss:  0.022818077355623245\n",
      "Batch:  300\n",
      "Task Loss:  0.16526399552822113\n",
      "Reconstruction Loss:  0.03836795687675476\n",
      "Cyclic Loss:  0.023000800982117653\n",
      "Batch:  600\n",
      "Task Loss:  0.2356153130531311\n",
      "Reconstruction Loss:  0.04275241121649742\n",
      "Cyclic Loss:  0.03283839300274849\n",
      "Batch:  900\n",
      "Task Loss:  0.34038013219833374\n",
      "Reconstruction Loss:  0.02606073021888733\n",
      "Cyclic Loss:  0.019583718851208687\n",
      "Batch:  1200\n",
      "Task Loss:  0.31747162342071533\n",
      "Reconstruction Loss:  0.027293406426906586\n",
      "Cyclic Loss:  0.01859261654317379\n",
      "Batch:  1500\n",
      "Task Loss:  0.22894613444805145\n",
      "Reconstruction Loss:  0.04158451035618782\n",
      "Cyclic Loss:  0.022568095475435257\n",
      "Elapsed Time:  524.8159888426463\n",
      "Epoch: 15\n",
      "Batch:  0\n",
      "Task Loss:  0.4460495710372925\n",
      "Reconstruction Loss:  0.033139150589704514\n",
      "Cyclic Loss:  0.023537658154964447\n",
      "Batch:  300\n",
      "Task Loss:  0.3036637604236603\n",
      "Reconstruction Loss:  0.03869318962097168\n",
      "Cyclic Loss:  0.02804112434387207\n",
      "Batch:  600\n",
      "Task Loss:  0.2953985631465912\n",
      "Reconstruction Loss:  0.04267819970846176\n",
      "Cyclic Loss:  0.03096400573849678\n",
      "Batch:  900\n",
      "Task Loss:  0.5230553150177002\n",
      "Reconstruction Loss:  0.038365840911865234\n",
      "Cyclic Loss:  0.024177145212888718\n",
      "Batch:  1200\n",
      "Task Loss:  0.2987492084503174\n",
      "Reconstruction Loss:  0.03787428140640259\n",
      "Cyclic Loss:  0.022519422695040703\n",
      "Batch:  1500\n",
      "Task Loss:  0.3373945355415344\n",
      "Reconstruction Loss:  0.036118872463703156\n",
      "Cyclic Loss:  0.02491767145693302\n",
      "Elapsed Time:  525.0448800623417\n",
      "Epoch: 16\n",
      "Batch:  0\n",
      "Task Loss:  0.36433538794517517\n",
      "Reconstruction Loss:  0.03379923477768898\n",
      "Cyclic Loss:  0.02502870187163353\n",
      "Batch:  300\n",
      "Task Loss:  0.35851287841796875\n",
      "Reconstruction Loss:  0.03840816766023636\n",
      "Cyclic Loss:  0.03017941117286682\n",
      "Batch:  600\n",
      "Task Loss:  0.41902801394462585\n",
      "Reconstruction Loss:  0.14202521741390228\n",
      "Cyclic Loss:  0.2590499222278595\n",
      "Batch:  900\n",
      "Task Loss:  0.2718566656112671\n",
      "Reconstruction Loss:  0.02522311732172966\n",
      "Cyclic Loss:  0.016251159831881523\n",
      "Batch:  1200\n",
      "Task Loss:  0.2913815379142761\n",
      "Reconstruction Loss:  0.02538830228149891\n",
      "Cyclic Loss:  0.017098257318139076\n",
      "Batch:  1500\n",
      "Task Loss:  0.3961256742477417\n",
      "Reconstruction Loss:  0.048296891152858734\n",
      "Cyclic Loss:  0.024283604696393013\n",
      "Elapsed Time:  525.2730357787188\n",
      "Epoch: 17\n",
      "Batch:  0\n",
      "Task Loss:  0.26163506507873535\n",
      "Reconstruction Loss:  0.04052204266190529\n",
      "Cyclic Loss:  0.02262493222951889\n",
      "Batch:  300\n",
      "Task Loss:  0.24583622813224792\n",
      "Reconstruction Loss:  0.03249174728989601\n",
      "Cyclic Loss:  0.024511059746146202\n",
      "Batch:  600\n",
      "Task Loss:  0.2558364272117615\n",
      "Reconstruction Loss:  0.03442032262682915\n",
      "Cyclic Loss:  0.02630443312227726\n",
      "Batch:  900\n",
      "Task Loss:  0.2435561716556549\n",
      "Reconstruction Loss:  0.039988916367292404\n",
      "Cyclic Loss:  0.030341366305947304\n",
      "Batch:  1200\n",
      "Task Loss:  0.20915023982524872\n",
      "Reconstruction Loss:  0.0361812599003315\n",
      "Cyclic Loss:  0.021004926413297653\n",
      "Batch:  1500\n",
      "Task Loss:  0.2901901304721832\n",
      "Reconstruction Loss:  0.03720451518893242\n",
      "Cyclic Loss:  0.022595344111323357\n",
      "Elapsed Time:  525.26675052113\n",
      "Epoch: 18\n",
      "Batch:  0\n",
      "Task Loss:  0.13000288605690002\n",
      "Reconstruction Loss:  0.025524601340293884\n",
      "Cyclic Loss:  0.024340376257896423\n",
      "Batch:  300\n",
      "Task Loss:  0.38041001558303833\n",
      "Reconstruction Loss:  0.031555917114019394\n",
      "Cyclic Loss:  0.026445146650075912\n",
      "Batch:  600\n",
      "Task Loss:  0.4924905300140381\n",
      "Reconstruction Loss:  0.34838080406188965\n",
      "Cyclic Loss:  0.6943874955177307\n",
      "Batch:  900\n",
      "Task Loss:  0.3053085207939148\n",
      "Reconstruction Loss:  0.02698642760515213\n",
      "Cyclic Loss:  0.018474340438842773\n",
      "Batch:  1200\n",
      "Task Loss:  0.24743229150772095\n",
      "Reconstruction Loss:  0.03413844481110573\n",
      "Cyclic Loss:  0.022285034880042076\n",
      "Batch:  1500\n",
      "Task Loss:  0.2801220417022705\n",
      "Reconstruction Loss:  0.031226135790348053\n",
      "Cyclic Loss:  0.024538589641451836\n",
      "Elapsed Time:  525.2754828929901\n",
      "Epoch: 19\n",
      "Batch:  0\n",
      "Task Loss:  0.2651211619377136\n",
      "Reconstruction Loss:  0.03568274527788162\n",
      "Cyclic Loss:  0.026718685403466225\n",
      "Batch:  300\n",
      "Task Loss:  0.30320143699645996\n",
      "Reconstruction Loss:  0.035358086228370667\n",
      "Cyclic Loss:  0.031214606016874313\n",
      "Batch:  600\n",
      "Task Loss:  0.5410662889480591\n",
      "Reconstruction Loss:  0.056716203689575195\n",
      "Cyclic Loss:  0.02881348691880703\n",
      "Batch:  900\n",
      "Task Loss:  0.30214130878448486\n",
      "Reconstruction Loss:  0.033344343304634094\n",
      "Cyclic Loss:  0.02260459028184414\n",
      "Batch:  1200\n",
      "Task Loss:  0.33170562982559204\n",
      "Reconstruction Loss:  0.0382843017578125\n",
      "Cyclic Loss:  0.024840621277689934\n",
      "Batch:  1500\n",
      "Task Loss:  0.322259783744812\n",
      "Reconstruction Loss:  0.03714675083756447\n",
      "Cyclic Loss:  0.029325803741812706\n",
      "Elapsed Time:  525.3733247041703\n",
      "Epoch: 20\n",
      "Batch:  0\n",
      "Task Loss:  0.3638056516647339\n",
      "Reconstruction Loss:  0.03932514786720276\n",
      "Cyclic Loss:  0.03279910609126091\n",
      "Batch:  300\n",
      "Task Loss:  0.38537096977233887\n",
      "Reconstruction Loss:  0.031755901873111725\n",
      "Cyclic Loss:  0.01958364248275757\n",
      "Batch:  600\n",
      "Task Loss:  0.2978965640068054\n",
      "Reconstruction Loss:  0.03988727554678917\n",
      "Cyclic Loss:  0.022386567667126656\n",
      "Batch:  900\n",
      "Task Loss:  0.3149098753929138\n",
      "Reconstruction Loss:  0.029414260759949684\n",
      "Cyclic Loss:  0.024501541629433632\n",
      "Batch:  1200\n",
      "Task Loss:  0.4557254910469055\n",
      "Reconstruction Loss:  0.03575960174202919\n",
      "Cyclic Loss:  0.02572452276945114\n",
      "Batch:  1500\n",
      "Task Loss:  0.29506656527519226\n",
      "Reconstruction Loss:  0.04142994433641434\n",
      "Cyclic Loss:  0.02935216575860977\n",
      "Elapsed Time:  525.4572737330482\n",
      "Epoch: 21\n",
      "Batch:  0\n",
      "Task Loss:  0.4546528458595276\n",
      "Reconstruction Loss:  0.03777647018432617\n",
      "Cyclic Loss:  0.0340881422162056\n",
      "Batch:  300\n",
      "Task Loss:  0.29759180545806885\n",
      "Reconstruction Loss:  0.08675576746463776\n",
      "Cyclic Loss:  0.06292834877967834\n",
      "Batch:  600\n",
      "Task Loss:  0.3337680697441101\n",
      "Reconstruction Loss:  0.028449442237615585\n",
      "Cyclic Loss:  0.01831611804664135\n",
      "Batch:  900\n",
      "Task Loss:  0.27199065685272217\n",
      "Reconstruction Loss:  0.036654699593782425\n",
      "Cyclic Loss:  0.018341509625315666\n",
      "Batch:  1200\n",
      "Task Loss:  0.31159770488739014\n",
      "Reconstruction Loss:  0.037532739341259\n",
      "Cyclic Loss:  0.020396387204527855\n",
      "Batch:  1500\n",
      "Task Loss:  0.3072483241558075\n",
      "Reconstruction Loss:  0.03287823125720024\n",
      "Cyclic Loss:  0.024486122652888298\n",
      "Elapsed Time:  525.517714381218\n",
      "Epoch: 22\n",
      "Batch:  0\n",
      "Task Loss:  0.5560699105262756\n",
      "Reconstruction Loss:  0.4995541572570801\n",
      "Cyclic Loss:  0.9744595885276794\n",
      "Batch:  300\n",
      "Task Loss:  0.2788255214691162\n",
      "Reconstruction Loss:  0.03203806281089783\n",
      "Cyclic Loss:  0.018513647839426994\n",
      "Batch:  600\n",
      "Task Loss:  0.31694620847702026\n",
      "Reconstruction Loss:  0.028878187760710716\n",
      "Cyclic Loss:  0.01960725151002407\n",
      "Batch:  900\n",
      "Task Loss:  0.34689176082611084\n",
      "Reconstruction Loss:  0.03657911717891693\n",
      "Cyclic Loss:  0.02336260862648487\n",
      "Batch:  1200\n",
      "Task Loss:  0.26137682795524597\n",
      "Reconstruction Loss:  0.03992515802383423\n",
      "Cyclic Loss:  0.021899389103055\n",
      "Batch:  1500\n",
      "Task Loss:  0.3115595579147339\n",
      "Reconstruction Loss:  0.031185545027256012\n",
      "Cyclic Loss:  0.019203735515475273\n",
      "Elapsed Time:  525.5149262262428\n",
      "Epoch: 23\n",
      "Batch:  0\n",
      "Task Loss:  0.4608510136604309\n",
      "Reconstruction Loss:  0.031788356602191925\n",
      "Cyclic Loss:  0.02141159027814865\n",
      "Batch:  300\n",
      "Task Loss:  0.3560546934604645\n",
      "Reconstruction Loss:  0.035713911056518555\n",
      "Cyclic Loss:  0.02570238523185253\n",
      "Batch:  600\n",
      "Task Loss:  0.26684731245040894\n",
      "Reconstruction Loss:  0.041561417281627655\n",
      "Cyclic Loss:  0.02878236211836338\n",
      "Batch:  900\n",
      "Task Loss:  0.5600769519805908\n",
      "Reconstruction Loss:  0.170011967420578\n",
      "Cyclic Loss:  0.1228763535618782\n",
      "Batch:  1200\n",
      "Task Loss:  0.25437214970588684\n",
      "Reconstruction Loss:  0.025722507387399673\n",
      "Cyclic Loss:  0.017469162121415138\n",
      "Batch:  1500\n",
      "Task Loss:  0.3896377384662628\n",
      "Reconstruction Loss:  0.031068332493305206\n",
      "Cyclic Loss:  0.01862618327140808\n",
      "Elapsed Time:  525.5480448206266\n",
      "Epoch: 24\n",
      "Batch:  0\n",
      "Task Loss:  0.20481130480766296\n",
      "Reconstruction Loss:  0.0366319939494133\n",
      "Cyclic Loss:  0.022830430418252945\n",
      "Batch:  300\n",
      "Task Loss:  0.2104853391647339\n",
      "Reconstruction Loss:  0.02798115462064743\n",
      "Cyclic Loss:  0.019077004864811897\n",
      "Batch:  600\n",
      "Task Loss:  0.23409661650657654\n",
      "Reconstruction Loss:  0.026258548721671104\n",
      "Cyclic Loss:  0.0184470247477293\n",
      "Batch:  900\n",
      "Task Loss:  0.2459453046321869\n",
      "Reconstruction Loss:  0.061427608132362366\n",
      "Cyclic Loss:  0.03258686885237694\n",
      "Batch:  1200\n",
      "Task Loss:  0.1898604929447174\n",
      "Reconstruction Loss:  0.040168896317481995\n",
      "Cyclic Loss:  0.03302453085780144\n",
      "Batch:  1500\n",
      "Task Loss:  0.17059695720672607\n",
      "Reconstruction Loss:  0.04070077836513519\n",
      "Cyclic Loss:  0.029251648113131523\n",
      "Elapsed Time:  525.6756361198426\n",
      "Epoch: 25\n",
      "Batch:  0\n",
      "Task Loss:  0.3217676877975464\n",
      "Reconstruction Loss:  0.026404080912470818\n",
      "Cyclic Loss:  0.020373212173581123\n",
      "Batch:  300\n",
      "Task Loss:  0.2019801139831543\n",
      "Reconstruction Loss:  0.02816123329102993\n",
      "Cyclic Loss:  0.017664896324276924\n",
      "Batch:  600\n",
      "Task Loss:  0.25918760895729065\n",
      "Reconstruction Loss:  0.03332517668604851\n",
      "Cyclic Loss:  0.02035406231880188\n",
      "Batch:  900\n",
      "Task Loss:  0.3511117994785309\n",
      "Reconstruction Loss:  0.026334673166275024\n",
      "Cyclic Loss:  0.020340580493211746\n",
      "Batch:  1200\n",
      "Task Loss:  0.2451191544532776\n",
      "Reconstruction Loss:  0.03532690182328224\n",
      "Cyclic Loss:  0.026107754558324814\n",
      "Batch:  1500\n",
      "Task Loss:  0.1540394127368927\n",
      "Reconstruction Loss:  0.031734075397253036\n",
      "Cyclic Loss:  0.018283655866980553\n",
      "Elapsed Time:  525.3878257733124\n",
      "Epoch: 26\n",
      "Batch:  0\n",
      "Task Loss:  0.32676562666893005\n",
      "Reconstruction Loss:  0.03070152923464775\n",
      "Cyclic Loss:  0.020089639350771904\n",
      "Batch:  300\n",
      "Task Loss:  0.270216166973114\n",
      "Reconstruction Loss:  0.031400926411151886\n",
      "Cyclic Loss:  0.022243278101086617\n",
      "Batch:  600\n",
      "Task Loss:  0.3593365550041199\n",
      "Reconstruction Loss:  0.03611624613404274\n",
      "Cyclic Loss:  0.026972582563757896\n",
      "Batch:  900\n",
      "Task Loss:  0.234746053814888\n",
      "Reconstruction Loss:  0.029883475974202156\n",
      "Cyclic Loss:  0.02706557884812355\n",
      "Batch:  1200\n",
      "Task Loss:  0.2205120325088501\n",
      "Reconstruction Loss:  0.0371859185397625\n",
      "Cyclic Loss:  0.03236212208867073\n",
      "Batch:  1500\n",
      "Task Loss:  0.2220839112997055\n",
      "Reconstruction Loss:  0.02723550610244274\n",
      "Cyclic Loss:  0.017551923170685768\n",
      "Elapsed Time:  525.4057101496944\n",
      "Epoch: 27\n",
      "Batch:  0\n",
      "Task Loss:  0.30923041701316833\n",
      "Reconstruction Loss:  0.027370505034923553\n",
      "Cyclic Loss:  0.016422586515545845\n",
      "Batch:  300\n",
      "Task Loss:  0.18217553198337555\n",
      "Reconstruction Loss:  0.03581645339727402\n",
      "Cyclic Loss:  0.019383084028959274\n",
      "Batch:  600\n",
      "Task Loss:  0.22903436422348022\n",
      "Reconstruction Loss:  0.02959098480641842\n",
      "Cyclic Loss:  0.021085357293486595\n",
      "Batch:  900\n",
      "Task Loss:  0.24972547590732574\n",
      "Reconstruction Loss:  0.0355561189353466\n",
      "Cyclic Loss:  0.023746976628899574\n",
      "Batch:  1200\n",
      "Task Loss:  0.2923213243484497\n",
      "Reconstruction Loss:  0.034876227378845215\n",
      "Cyclic Loss:  0.02509165182709694\n",
      "Batch:  1500\n",
      "Task Loss:  0.6332241296768188\n",
      "Reconstruction Loss:  0.2189776748418808\n",
      "Cyclic Loss:  0.2622196078300476\n",
      "Elapsed Time:  525.5467911532947\n",
      "Epoch: 28\n",
      "Batch:  0\n",
      "Task Loss:  0.31476086378097534\n",
      "Reconstruction Loss:  0.025988560169935226\n",
      "Cyclic Loss:  0.017170365899801254\n",
      "Batch:  300\n",
      "Task Loss:  0.38186022639274597\n",
      "Reconstruction Loss:  0.029295170679688454\n",
      "Cyclic Loss:  0.018740005791187286\n",
      "Batch:  600\n",
      "Task Loss:  0.41474953293800354\n",
      "Reconstruction Loss:  0.03740040212869644\n",
      "Cyclic Loss:  0.020268691703677177\n",
      "Batch:  900\n",
      "Task Loss:  0.4450703263282776\n",
      "Reconstruction Loss:  0.028483036905527115\n",
      "Cyclic Loss:  0.022646451368927956\n",
      "Batch:  1200\n",
      "Task Loss:  0.35953783988952637\n",
      "Reconstruction Loss:  0.02654622122645378\n",
      "Cyclic Loss:  0.017881259322166443\n",
      "Batch:  1500\n",
      "Task Loss:  0.27254992723464966\n",
      "Reconstruction Loss:  0.031367793679237366\n",
      "Cyclic Loss:  0.01676172949373722\n",
      "Elapsed Time:  525.4762605058736\n",
      "Epoch: 29\n",
      "Batch:  0\n",
      "Task Loss:  0.27033084630966187\n",
      "Reconstruction Loss:  0.03425481542944908\n",
      "Cyclic Loss:  0.019980017095804214\n",
      "Batch:  300\n",
      "Task Loss:  0.28640979528427124\n",
      "Reconstruction Loss:  0.033088378608226776\n",
      "Cyclic Loss:  0.022886812686920166\n",
      "Batch:  600\n",
      "Task Loss:  0.34186917543411255\n",
      "Reconstruction Loss:  0.031016556546092033\n",
      "Cyclic Loss:  0.02382218837738037\n",
      "Batch:  900\n",
      "Task Loss:  0.42960894107818604\n",
      "Reconstruction Loss:  0.03736920654773712\n",
      "Cyclic Loss:  0.027626046910881996\n",
      "Batch:  1200\n",
      "Task Loss:  0.418229877948761\n",
      "Reconstruction Loss:  0.03601169213652611\n",
      "Cyclic Loss:  0.021566202864050865\n",
      "Batch:  1500\n",
      "Task Loss:  0.37719225883483887\n",
      "Reconstruction Loss:  0.039197586476802826\n",
      "Cyclic Loss:  0.02168777957558632\n",
      "Elapsed Time:  525.5454111178716\n",
      "Epoch: 30\n",
      "Batch:  0\n",
      "Task Loss:  0.2843000590801239\n",
      "Reconstruction Loss:  0.02806374989449978\n",
      "Cyclic Loss:  0.021793516352772713\n",
      "Batch:  300\n",
      "Task Loss:  0.2881038784980774\n",
      "Reconstruction Loss:  0.038842495530843735\n",
      "Cyclic Loss:  0.024634024128317833\n",
      "Batch:  600\n",
      "Task Loss:  0.23170369863510132\n",
      "Reconstruction Loss:  0.040267422795295715\n",
      "Cyclic Loss:  0.030210288241505623\n",
      "Batch:  900\n",
      "Task Loss:  0.5244385600090027\n",
      "Reconstruction Loss:  0.03941066935658455\n",
      "Cyclic Loss:  0.03437580168247223\n",
      "Batch:  1200\n",
      "Task Loss:  0.2805904448032379\n",
      "Reconstruction Loss:  0.03039458394050598\n",
      "Cyclic Loss:  0.01914624124765396\n",
      "Batch:  1500\n",
      "Task Loss:  0.2725125551223755\n",
      "Reconstruction Loss:  0.03301290422677994\n",
      "Cyclic Loss:  0.020608922466635704\n",
      "Elapsed Time:  525.6668723937004\n",
      "Epoch: 31\n",
      "Batch:  0\n",
      "Task Loss:  0.39060771465301514\n",
      "Reconstruction Loss:  0.03754753619432449\n",
      "Cyclic Loss:  0.024360740557312965\n",
      "Batch:  300\n",
      "Task Loss:  0.1778278648853302\n",
      "Reconstruction Loss:  0.04801550880074501\n",
      "Cyclic Loss:  0.029444703832268715\n",
      "Batch:  600\n",
      "Task Loss:  0.38883012533187866\n",
      "Reconstruction Loss:  0.17569108307361603\n",
      "Cyclic Loss:  0.4310004413127899\n",
      "Batch:  900\n",
      "Task Loss:  0.2530146837234497\n",
      "Reconstruction Loss:  0.03291722759604454\n",
      "Cyclic Loss:  0.019250284880399704\n",
      "Batch:  1200\n",
      "Task Loss:  0.3414018750190735\n",
      "Reconstruction Loss:  0.04586305469274521\n",
      "Cyclic Loss:  0.02180425450205803\n",
      "Batch:  1500\n",
      "Task Loss:  0.40986043214797974\n",
      "Reconstruction Loss:  0.044672105461359024\n",
      "Cyclic Loss:  0.025356652215123177\n",
      "Elapsed Time:  525.5568085983396\n",
      "Epoch: 32\n",
      "Batch:  0\n",
      "Task Loss:  0.27047306299209595\n",
      "Reconstruction Loss:  0.03382383659482002\n",
      "Cyclic Loss:  0.028477441519498825\n",
      "Batch:  300\n",
      "Task Loss:  0.43881893157958984\n",
      "Reconstruction Loss:  0.04431796073913574\n",
      "Cyclic Loss:  0.031471963971853256\n",
      "Batch:  600\n",
      "Task Loss:  0.34201428294181824\n",
      "Reconstruction Loss:  0.0407240092754364\n",
      "Cyclic Loss:  0.029121482744812965\n",
      "Batch:  900\n",
      "Task Loss:  0.34587037563323975\n",
      "Reconstruction Loss:  0.04158559814095497\n",
      "Cyclic Loss:  0.02374310791492462\n",
      "Batch:  1200\n",
      "Task Loss:  0.28145313262939453\n",
      "Reconstruction Loss:  0.031245771795511246\n",
      "Cyclic Loss:  0.026854606345295906\n",
      "Batch:  1500\n",
      "Task Loss:  0.3031894266605377\n",
      "Reconstruction Loss:  0.03160828351974487\n",
      "Cyclic Loss:  0.026606695726513863\n",
      "Elapsed Time:  525.5523224671682\n",
      "Epoch: 33\n",
      "Batch:  0\n",
      "Task Loss:  0.18399937450885773\n",
      "Reconstruction Loss:  0.039095841348171234\n",
      "Cyclic Loss:  0.022494932636618614\n",
      "Batch:  300\n",
      "Task Loss:  0.21518218517303467\n",
      "Reconstruction Loss:  0.03379688411951065\n",
      "Cyclic Loss:  0.020220689475536346\n",
      "Batch:  600\n",
      "Task Loss:  0.16364449262619019\n",
      "Reconstruction Loss:  0.03416059538722038\n",
      "Cyclic Loss:  0.021485816687345505\n",
      "Batch:  900\n",
      "Task Loss:  0.27344608306884766\n",
      "Reconstruction Loss:  0.03320242464542389\n",
      "Cyclic Loss:  0.02708417922258377\n",
      "Batch:  1200\n",
      "Task Loss:  0.3337108790874481\n",
      "Reconstruction Loss:  0.037417519837617874\n",
      "Cyclic Loss:  0.02900778502225876\n",
      "Batch:  1500\n",
      "Task Loss:  0.3845682740211487\n",
      "Reconstruction Loss:  0.08249015361070633\n",
      "Cyclic Loss:  0.3391570448875427\n",
      "Elapsed Time:  525.5462841216256\n",
      "Epoch: 34\n",
      "Batch:  0\n",
      "Task Loss:  0.27836811542510986\n",
      "Reconstruction Loss:  0.03214341774582863\n",
      "Cyclic Loss:  0.0182094294577837\n",
      "Batch:  300\n",
      "Task Loss:  0.23853066563606262\n",
      "Reconstruction Loss:  0.026784243062138557\n",
      "Cyclic Loss:  0.01805168204009533\n",
      "Batch:  600\n",
      "Task Loss:  0.22879460453987122\n",
      "Reconstruction Loss:  0.03224696218967438\n",
      "Cyclic Loss:  0.019885636866092682\n",
      "Batch:  900\n",
      "Task Loss:  0.35043394565582275\n",
      "Reconstruction Loss:  0.036867160350084305\n",
      "Cyclic Loss:  0.019579164683818817\n",
      "Batch:  1200\n",
      "Task Loss:  0.13016138970851898\n",
      "Reconstruction Loss:  0.03991430625319481\n",
      "Cyclic Loss:  0.020518574863672256\n",
      "Batch:  1500\n",
      "Task Loss:  0.26174819469451904\n",
      "Reconstruction Loss:  0.03793634474277496\n",
      "Cyclic Loss:  0.025406261906027794\n",
      "Elapsed Time:  525.5225692885263\n",
      "Epoch: 35\n",
      "Batch:  0\n",
      "Task Loss:  0.32512733340263367\n",
      "Reconstruction Loss:  0.39689046144485474\n",
      "Cyclic Loss:  1.1130083799362183\n",
      "Batch:  300\n",
      "Task Loss:  0.3603573441505432\n",
      "Reconstruction Loss:  0.03334025293588638\n",
      "Cyclic Loss:  0.019866839051246643\n",
      "Batch:  600\n",
      "Task Loss:  0.2784648835659027\n",
      "Reconstruction Loss:  0.039487045258283615\n",
      "Cyclic Loss:  0.023309478536248207\n",
      "Batch:  900\n",
      "Task Loss:  0.3524673581123352\n",
      "Reconstruction Loss:  0.0358741469681263\n",
      "Cyclic Loss:  0.02331283502280712\n",
      "Batch:  1200\n",
      "Task Loss:  0.43686527013778687\n",
      "Reconstruction Loss:  0.03526723012328148\n",
      "Cyclic Loss:  0.026195818558335304\n",
      "Batch:  1500\n",
      "Task Loss:  0.26767784357070923\n",
      "Reconstruction Loss:  0.09783843159675598\n",
      "Cyclic Loss:  0.045239079743623734\n",
      "Elapsed Time:  525.5575007796288\n",
      "Epoch: 36\n",
      "Batch:  0\n",
      "Task Loss:  0.3278205394744873\n",
      "Reconstruction Loss:  0.033202797174453735\n",
      "Cyclic Loss:  0.02281254157423973\n",
      "Batch:  300\n",
      "Task Loss:  0.21786820888519287\n",
      "Reconstruction Loss:  0.03348686918616295\n",
      "Cyclic Loss:  0.022787069901823997\n",
      "Batch:  600\n",
      "Task Loss:  0.16792814433574677\n",
      "Reconstruction Loss:  0.036443840712308884\n",
      "Cyclic Loss:  0.030046233907341957\n",
      "Batch:  900\n",
      "Task Loss:  0.3988499641418457\n",
      "Reconstruction Loss:  0.02935425564646721\n",
      "Cyclic Loss:  0.020231422036886215\n",
      "Batch:  1200\n",
      "Task Loss:  0.0857277661561966\n",
      "Reconstruction Loss:  0.024504324421286583\n",
      "Cyclic Loss:  0.018966037780046463\n",
      "Batch:  1500\n",
      "Task Loss:  0.27611568570137024\n",
      "Reconstruction Loss:  0.03641144558787346\n",
      "Cyclic Loss:  0.021205903962254524\n",
      "Elapsed Time:  525.5789265825941\n",
      "Epoch: 37\n",
      "Batch:  0\n",
      "Task Loss:  0.35047292709350586\n",
      "Reconstruction Loss:  0.03257143124938011\n",
      "Cyclic Loss:  0.02347561903297901\n",
      "Batch:  300\n",
      "Task Loss:  0.19242113828659058\n",
      "Reconstruction Loss:  0.04056446626782417\n",
      "Cyclic Loss:  0.03212974593043327\n",
      "Batch:  600\n",
      "Task Loss:  0.30949127674102783\n",
      "Reconstruction Loss:  0.03270549699664116\n",
      "Cyclic Loss:  0.019548209384083748\n",
      "Batch:  900\n",
      "Task Loss:  0.23070864379405975\n",
      "Reconstruction Loss:  0.028575899079442024\n",
      "Cyclic Loss:  0.018323885276913643\n",
      "Batch:  1200\n",
      "Task Loss:  0.1525106430053711\n",
      "Reconstruction Loss:  0.022368604317307472\n",
      "Cyclic Loss:  0.017364755272865295\n",
      "Batch:  1500\n",
      "Task Loss:  0.20061573386192322\n",
      "Reconstruction Loss:  0.04451934993267059\n",
      "Cyclic Loss:  0.021665871143341064\n",
      "Elapsed Time:  525.5871828606254\n",
      "Epoch: 38\n",
      "Batch:  0\n",
      "Task Loss:  0.2904698848724365\n",
      "Reconstruction Loss:  0.04399842768907547\n",
      "Cyclic Loss:  0.026124324649572372\n",
      "Batch:  300\n",
      "Task Loss:  0.36850932240486145\n",
      "Reconstruction Loss:  0.04780985414981842\n",
      "Cyclic Loss:  0.026667486876249313\n",
      "Batch:  600\n",
      "Task Loss:  0.1865256428718567\n",
      "Reconstruction Loss:  0.09474000334739685\n",
      "Cyclic Loss:  0.09696435183286667\n",
      "Batch:  900\n",
      "Task Loss:  0.4406242072582245\n",
      "Reconstruction Loss:  0.028897851705551147\n",
      "Cyclic Loss:  0.017912235110998154\n",
      "Batch:  1200\n",
      "Task Loss:  0.2231614589691162\n",
      "Reconstruction Loss:  0.04592343047261238\n",
      "Cyclic Loss:  0.022627592086791992\n",
      "Batch:  1500\n",
      "Task Loss:  0.24084293842315674\n",
      "Reconstruction Loss:  0.03675297275185585\n",
      "Cyclic Loss:  0.022111359983682632\n",
      "Elapsed Time:  525.5515950459701\n",
      "Epoch: 39\n",
      "Batch:  0\n",
      "Task Loss:  0.3791325092315674\n",
      "Reconstruction Loss:  0.03686567023396492\n",
      "Cyclic Loss:  0.029370229691267014\n",
      "Batch:  300\n",
      "Task Loss:  0.30059814453125\n",
      "Reconstruction Loss:  0.03635246306657791\n",
      "Cyclic Loss:  0.02910127304494381\n",
      "Batch:  600\n",
      "Task Loss:  0.23764052987098694\n",
      "Reconstruction Loss:  0.036847129464149475\n",
      "Cyclic Loss:  0.019334619864821434\n",
      "Batch:  900\n",
      "Task Loss:  0.2331458330154419\n",
      "Reconstruction Loss:  0.023939242586493492\n",
      "Cyclic Loss:  0.015512729994952679\n",
      "Batch:  1200\n",
      "Task Loss:  0.36612504720687866\n",
      "Reconstruction Loss:  0.03072326071560383\n",
      "Cyclic Loss:  0.016085045412182808\n",
      "Batch:  1500\n",
      "Task Loss:  0.29164373874664307\n",
      "Reconstruction Loss:  0.03870755806565285\n",
      "Cyclic Loss:  0.019776033237576485\n",
      "Elapsed Time:  525.5668435692787\n"
     ]
    }
   ],
   "source": [
    "train(Encoder,phi,invphi,train_load,num_epochs=40)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glass_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=torch.randperm(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
