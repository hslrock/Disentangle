{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules import EncoderNet,DecoderNet,DiscriminatorNet_reconstruction,GeneratorNet\n",
    "from network import transformNet\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "#import resnet\n",
    "#import invresnet\n",
    "from dataload import load_data ,batchfy \n",
    "from torchsummary import summary\n",
    "import torch\n",
    "from torch import nn,optim\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import time\n",
    "from torchvision import transforms, utils\n",
    "TIMEOUT=300\n",
    "#Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.set_default_tensor_type(torch.cuda.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Encoder=torch.load(\"Encoder_64batch.h\")\n",
    "Decoder=torch.load(\"Decoder_64batch.h\")\n",
    "#Encoder=resnet.resnet18()\n",
    "#Encoder=Encoder.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD7CAYAAACscuKmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO29aaxl2XUe9q0z3OHNQw1d1dXNqh7YbJo2m3KDIkPFoClLpmXD/CMZlo2ASQj0H9mQEBsimSCBHSSA9MdSfgQKGqFi/lBMyYNCgjBs0R1RQmCJZNMkRVLNnrvZ1TW8Gt54xzPs/Lj33fWt9d6remRV3aJ59wcU6tx39j1nn33Ovmet/a31LQkhICIi4scfyf3uQERExHQQJ3tExIwgTvaIiBlBnOwRETOCONkjImYEcbJHRMwI7miyi8hHReRFEXlFRD51tzoVERFx9yE/LM8uIimAlwD8DICLAL4G4BdDCH9+97oXERFxt5DdwXffD+CVEMJrACAinwPwMQBHTvb5RhbW5poAAP8jYz/bfUL2h/DfRUy7JElxeEt7fPs91w/6nCb2GPy1EOqjTmUPeasfU7erqvkPetCDP8hHH5PbcqvEjRXvq2s33sLbOvhJag3BRHS8D14m9UOO7q/QGB+8n3o+SVNq5/qRZvQd+0jzM5FyO3ctfA/DgWfHdNh9je4TboVw6Cbgx/uI87qv+bHab/zWpSu4ubnln0gAdzbZHwTwFn2+COAnb/WFtbkmfuWnngQAlFVl9pXlYLItYvflDXogoJOsmTdNu7n5hcl2IvbShkU52c4auq+uC9MuQNvNzee2H7n2oyx7eq7ETZZKP5eDodmXgs9tv7e319cPiZ67KEvTrq70s3/AikLHMQR90BtNey38w9If2DFIUr3OVmt+sj23MGfaNZu6r7KHQEU9q0V3SmZ7nDW1j1nL9rE5p+drzS/Rd+ZNu4XFde3j4kmzr9FanGwvr1K7ZXstoB+JKqRmV1nTj07SsF9L9XMddNzqujbtAvSZlmD35Tn9INGzVFW2XUXHTzM7Vvvn+7m/89/iKNyJz37Yr8eBHzcReUZEnheR5zvD8pCvRERETAN38ma/COAh+nwOwCXfKITwLIBnAeBkuxlefu06AKAM9u1d0Rs1zZ1pnei+OuhbwprtQCr0K1vZYyzQG6qR66+ityKC6LkaTft71mjqcGVkfrZbdhgbqR6fDBYAABkHWGjbN1R7Xt9CN3f0Lb+9vWvaDXtqVTSb9vear41ft9u7fdNuQNaCt4LYfN7d1O+lyZZpNzenllS7uWj2sYmPlO5t073xWrpd9u2+/t5N7UemfWzN23MNu9pub/uq2SepWn9bN9Ym2w88+LBpN7e4MtlutJfMvoze5rV/xwVyc8gaq917ryr0XgT3ZpdUPwuNfQ3bbjjUZ9UZSEhTOxcOw5282b8G4HERuSAiDQB/F8AX7uB4ERER9xA/9Js9hFCKyD8A8O8BpAB+O4Tw3bvWs4iIiLuKOzHjEUL4twD+7V3qS0RExD3EHU32HxQBCfqhDQAonT9Sp7QKGayjOxior9IvyMd27lOrrX9oJC2zb9BXjyUdkI8k3n/SY+RuhTkfaB8T8kPnCusvrSyon1hX1lPqd9QHTrZ27AlotRWZrhZn83aFOU/UV97bvWH2VTvdyXaL/PdGbtcHxIy3HciCHosBra044gL9Aa1NdLpmnxBvlNOaS95wq/E5LdqmlrlIcr03C8va/8GgY9pV5d5kuz2/bDtJ6xF7OxuT7bqy51o+8cBke5W2AaC9qL4++9QAUNGgsN/caFqmKMl0jIvCDmRFcyHQWkrlWZhwtNe9T7neiv6L4bIRETOCONkjImYEUzXjyyrgxu7IhElze+q0rSZQz/FVbFYOoTRI4Wj7LrFLzYb9HcvIcqoHZCpV9lyBTKrE8RsNOmaDAnNWV5wZTLRTK7PuRB8UdebMNPZsOjtqqqaOYmzTuZNswewb0uX0O3rRWe6CeyggqbDsI2qKNOtVeu5B6VyvggJzCnt8jkRMyBVIgr1m/pwltiMpUVJ5pu5Ko2Xv7cKymvFLtA0A8ws6/otLSq8lqWWJK6JqOdJu1FafuaztzHiKDizpGWu4CL28occQF5lZkUvB4ybObG/lei15boN79oNqDkTWEeKbPSJiRhAne0TEjCBO9oiIGcFUffYaAb2xb9F0+4QSEfKG9XMT+k1K6ZtSupBbSlgoHB0WAiWgkN88PJB5RjSIy+6QUo+f0/G3epZ2unhNFw9aLlmnQfRM7sNUwQk/5FP37bqC7OrnuYa9zrmmUk9JU/3h/tAeY9jRfYUfA3L7Chq3vsttGNT6uVfZcFxOhEmN/279/pQSchL37uGw40au+8KOvS/5th6jNe8otWU9xvq69vf6xmumXXvu4mT7wta22XfuvF7bkqPl5ldOTbZLonEH7tnEvFKHBzI+eUhukWWYpUdP1+Okqsc3e0TEjCBO9oiIGcFUzXhJEjSXRib6cGDNPqGMnvl51y1Rk5bNlUVHwQhFzWUNGzFWl2qb9vpqBg4HzryttR/dfs/sY3qpIJO79mYZcTCpz83PKMoq8cNPgg/Uj3bb5e032pPtsrKmdbfDedOUU+5ytDn3euDs+ILMyoLysIPYHOqSxmDozPNAJi2PT1I7HQM6tT06wE0roqtCbcetR67AZte6VNe29P5euqbZgycX7DEWF/Tsw4F9rq5c0ay6Uw88aPY9+sRfmGyvnz4z2Wa6DgDqHb0Yzs0HgIqy6rqU0Zg1rTtbk9s3GDodhvFz4DUSGPHNHhExI4iTPSJiRjBVM76qStzYHplELRfhttjUxA+BNa2XaSWz1VCTNnOmUiPXaLLgjMLtnprgbTpGHWwEWn+o7Xa71nzukMnPq/ZDJz1VJLqvdOZtRcv/PRe9xxF0PVo9T3atO7FCohENN44Jmd0ZRVNlmWcnKJLPrfp2KVFjWLIZb7sL+l6/tMdgN4HtcXHZSwmb+C6Ng3KSkFachOS0AY1en+1ioDDLXYqc3Nu1x5gjYZKrm9Y1mpvX1fn1izZ56bW3NbLv9Jmzk+13v+c9pt0DZ89NtvtdK0aSZPoczzfVRctdMs3NXf1e4WTd8vz2Uzm+2SMiZgRxskdEzAjiZI+ImBFM1WdPsxQr6yOxwAdPnzD7yp76I4kTr5hrkbhjRpSOy7Qqdzcn292uyyijqLycZHj3XHTa7q5mm3mJ5TTT38aMso4ysRQJu6X9nhPi6CvlWDupYJaMDuRv+6y0K1sq/JgfiLI6XBPfR65xlOL8vF23KGi9o0M+ew2XsVbruargiDPuBolXoPaPHImJOhrRZCDSdpbZYwjfJufPs468UGhgt2fHY66v7Tpu/WGOfP1C7P28uqNq6l//sxcn2ze2bfbdB/8LVVk/ccqKkbRp6SkhirHXtcdokMx05rLb9uWok6OT3uKbPSJiVhAne0TEjGCqZnyWpVhbGyVqrKxa7e/rhZqmTUcjFJRk0euoGVX2rBmPgkzfoaWaOmQLl0RDlT6yjCke1/+KzLtAggyt3FYXYfYnn7f0SYt03suBNVvZjOcrKx1dVZGIRHD6+8YUJjPb6U6g01E6r1davkpSThoiWsubiFz5pnQCdYSMNc297Lrw8d29ILM1pXaVo+iGJHZSDe14kOcFMcIh1u0Iqboytdu3s6nH7xTWtF5YVHdob09d0T/40h+bdpc3VM/+/T/5E2bfE+96fLK9sqICG6lzSTgy07s8ddgvq+Z8PkJ8s0dEzAjiZI+ImBHEyR4RMSOYqs/eaDbxyIVHAABVZbOTTpwmOqK24aFcgJQrpFaOk0qCchj9Pbtvrqd+f5cyhm5u2/DHgvyi0jmpQmIKIbBwg/VXmxTmWDkRAyHBh9U1m/3UpFBJ9tN7TngikMCBDz8tKDyUM/rYRweAgny+gaMYh139Xk066ZmrHBoCq3ge7SuCRDcP1ECj+ym5ffeYktMU4lw5GpGT9opg13EqWgfgsUocfXeT1k8aLnMskCDk7tAef43a5lRX7roTwPijP/rTyfYrr7xi9j3xrkcn249c0Bp0jz163rQ7f+4sfbJ9LMfPSLjFfbjtm11EfltENkTkO/S3NRH5koi8PP5/9XbHiYiIuL84jhn/zwF81P3tUwCeCyE8DuC58eeIiIgfYdzWjA8h/LGInHd//hiAD4+3PwvgywA+ebtjLS8t4Wf/+s8CALpdaz5zGaChozdaFKDGgUNS+4wvNeM7O9b03bymAgS9PY2S6/SsiMb1m0qfbO7Y7KSCIrCGRFcNnTsxJFNvbq5t9p1/xzsm22cfPGv2NSgqrzWndJ7PfuJByJx++JBclF5XTfdt565sXL8+2b5y1ZY5vnz5ymT77cu6r++iDbmMUeWi60qiEbtUGspV0jYiINnQPo7srpRkLpcutY0t19Rp/oUjMuJc8CKGpT4HfWcJt4gKThPrytwkPcBQ6HO16CjXgk74+pt2vK9d08jPb/6niQGNB8/aSLu/SOb+2dOnzL7VE6MSVcO+fZ4ZP+wC3ekQwmUAGP9/6jbtIyIi7jPu+Wq8iDwjIs+LyPNbu7u3/0JERMQ9wQ+7Gn9VRM6EEC6LyBkAG0c1DCE8C+BZAHj3Ox8NC+ujCKGGM3Maua6a+hXbLOfSPCS3nNh2A9KW69W2uunWxcuT7T6ZOifW1k27dzzy2GS7vbBi9gU5XI66OWf17lptNd3n29aM5yKgqUtiaVKJIBZyqN1qP+uMeXO0JFGNkgQOSscKFGTul04IoUNm9/UbOo5vX7ps2r32msoxv/TSC2bftavXJtvDwLLVNkquwZkbLrquS4lOfV4Ed+WwYCLj7B4zPjRujZY1xznKjwVAAIAL8XYGlkVKiRloEFux1XFy18xqJPbZ393RfnWpyu/erh3vvW11GR5+8LrZd2Jsxne6d9+M/wKAj4+3Pw7g8z/kcSIiIqaE41Bv/wLAnwB4QkQuisgnAPwagJ8RkZcB/Mz4c0RExI8wjrMa/4tH7Prpu9yXiIiIe4ipRtABQD0ucVscEBdUP6bVshlxea5+b00+Ug3rsF7a0MikP/6Pf2b2ffVPNIIpI99t3Qk3nF7R8klrqzZW6OxDD022l06q+MZjZ06bdnN0zGbLCls0GurXZc73HA6UukFBJaQsu2Z89tr77JyJlvC2bbeyoH0snAjI8pw+FqfXtd0TFyxV+Jf/oq5v9LofNPtu3FCf8tvfU1GH775oo8deu6g038Blzs3ThQ/I+e4Xth1Xvs4y6w9z+eWa1geGhY0oNM6+E4ZoZEdPE9bErwuuF+BKO9O6gj8aPwVC86LTsWsH165/f7L94stvmX1Li6M5sr1jaWtGjI2PiJgRxMkeETEjmLoZPzFTHGckZJqKr+ZJ5Y76lLCws2ujwv7kq9+abH/la9aMv76jZltClUkHTudrua10WzuxJvgjD6gZe+Ksmu6L87bdDoltlJWr1JooTSdO975NUXMpJXRI1THtKhJrGLrEDBafT4nuabokkwG5DLUrJVQNdKyETNqGEzhbausxW54Oq9Rdefq9Ks7wvve92zR7+6pGNn7bmfjfffH1yfb1m3qfmk7UITXVb617yLr0acKJMC6ph47B0X+AL1XmqMOUs7RIFMUJgpSmqq3tf0bH5MqtuaMiuYhu4TjG/th9K32IIiG+2SMiZgRxskdEzAjiZI+ImBFM12cPYVJathjasL6M9L3nnGgeiw3OUfjp5atXTLtXX9XwTc7cAgAhX6gmgQcsLZt2p6kk7/lHLph9Z6heV0rhlteu29DFirLUGpn155tGVNH67EL+fR1IoMLxazWJdEjqBDxEr60sSISisr59SiGbiXMOUyq3HEhso3IiGmVf10yKnl0/SUmcJKE1jABLjV14h659nH/UjvdP/GUN1X39LY3IfvHlN0y7N97UsNLNLbu+wexsQpr1A5fBl6QkQpFbfz6/BfVmM+nYj7a+vbDARu39eb2H/PYtEi/mof0o3dTdP3V9QBVUEd/sEREzgjjZIyJmBFM34zGO1hq4srWBBCCW520mWkXmaGNOTdjt7S3TbpcEGnxZXxaY4LJLzXmr+X7irJrxjQUbyTckEymQbtv1TWvCttc08i6ft/2oC7IrPbfCv72ipmQt1twPwtFejvJifTo6XKhdPygS0UuN8/jURPMN+pamrArKACvs/cxLbduqKXvNuRNlrePYWrbX8sQjKvTx7ncpZfdf/pTt8OUrSt+9+NLrZt+br1/UdpSJt3nTPjtd0ugLXgKfhs5r13HiYkkqGpXLnONjuMQ/TsZDQpSa1K7MNmvFO2qvP/ZX6jpSbxERM4842SMiZgRTNeMDAqpxskOvY1dNh4naTv0lay5mtKKdkAZYz2nE7ZESTu1KK+3t6TE5WWLgRB0W19Ym2/NrVgMsaWlSSIdM2spp4aUpVYx1UXImwMtpqZn8C97lkiqCWaW9xeorV/1MvPyymogHBDBKTu4g09TLFLO5X3lxDDWLB3Sv+05cQhqUiNS0LtXckkYzZhQB2GpYQZDT63qf3vPkE2bfzq724+ZNlXe+fMXqrbz5ppr733/zTbPvxRdfmmzvOfdTjihLFVwyjakue0B8Q2FGsbaDlXIUpGNo9u9ZQDTjIyJmHnGyR0TMCOJkj4iYEUzXZ68DynGG1bDfdXs1ympn+6bZ025rplhBkUktV9q5yX6S88XXV5QOGxD91WpZP3GBBCjby1ZwElSeqbfToT/bMk5zbaXsGk7HnF3nxPnsHGZV8T7ns7PYpYineA4XcDzgQ5LfH5zfz6KVRcmilc7vZxENRw9KrmOQtUgQcs+KRnDWXmNo93HUX0p0Y+a14WlQfbRb84Tem/U1jZZ8/LHzth8f1DLK3Y71y69saDTmSy99z+z70z/9k8n2y1TWqU5tPzhoM9R2rBJa1wlHUKcAUHFGIxzS8b6jl3Dimz0iYlYQJ3tExIxgyuIVAfucUu10xAqieDo71ozfa6kZv7jEWl7WDH6AaLPrGzYR5sQDmnBRUDTZE++0VM3D589PtlNnLA1Zr50SSVgjDwCaufY3g02qYG7F/9IyVVZxJJQ3wY+i6GA10QKZ47WjargQanUggo62aaxC7R4X0tGX1GrnNygyMZ8nM3vBum+DUk31vGmThmpTkVU71W7Z+1JTPyoXdZZl87SPxtcJVDQyvRtzuXXLVpf0/j5yzhY/evqpJyfbN25qQtT/8ZnfNu2uXNOIvZ6jhWt6EipKCAtuemY4mnKVfffFPyuE+GaPiJgRxMkeETEjiJM9ImJGMFWfXSRBYxyq2mi4TC4SOOg5Icm9pvrwbQqVbLvMtvVl9bVOLtuMtZNL+nmdBCouXDhv2rHO+MKS1Y3vUR2tkHWpnfXxWCDTSdsjy0hc0P3UJiQawTSLF1Hkgx7wxckBryr2Ua1j3h9oNpvXjWeKjevbpU27NsHUZ+libpk6ZAot8bXeMu1H3nCCD3SdVanjnYob70yfg77T3+RMsYQe9+B4LaE1gcKLoZJ/nzm6dH1Rn6tFqhHwP/7jXzXtnv/Gtyfb/+GP/qPZ99obb9O56flwa0GgenQHg2LH++5EvEJEHhKRPxSRF0TkuyLyy+O/r4nIl0Tk5fH/q7c7VkRExP3Dccz4EsA/CiE8CeADAH5JRN4N4FMAngshPA7gufHniIiIH1Ecp9bbZQCXx9u7IvICgAcBfAzAh8fNPgvgywA+eatjiQAyNkWaDRsFVfTURDZlkAD0d5W2qBY1qm2xabt/Zl0jpDYWLRU0T+bzWYqmO3vCCmUsEmXUbFkz6uYWCTLMqynpy1VlFBFVV1Zrz2iXOxu/R+WAuYRwObRUTUW0ZeaoloSUKIYUkVZXju6hYxReN57MWKF+5A1LjXH57NrRlCWZkyWVWiqd2EbV10y0wdDScl2Ksgxbm5Pt7S0b4baydmay3WhaAzPQGAfS7qtdBp+Ax8Del5yuJfFhbWw2k4k/dK7AU+9652T71Ip95l54SbUTv/FtLX39/bevmnaDIdGgTidPmbi7lPUmIucBvA/AVwCcHv8Q7P8gnDr6mxEREfcbx57sIrIA4F8D+JUQws7t2tP3nhGR50Xk+c1bFJ2LiIi4tzjWZBeRHKOJ/jshhH8z/vNVETkz3n8GwMZh3w0hPBtCeDqE8PTq0sJhTSIiIqaA2/rsMpLi+AyAF0II/4x2fQHAxwH82vj/z9/+dAmSZOQ3zc3ZbLNhj9RMXGbUoKv7StpecH7/A2vqz19csP52SSWQb7yt5W5PnLRqNDnxYbmrByakMDI3p8fPXDuQ5nsmbohJfWTgdNh7fb02it5E7muDkZ8+dFwTRdyaMfXKQFwHToL9zWfKMSFaK3FcYaOtPvywsL5ib0ghsm39kc9b9p5t39TvXduwIpA3rmnI816HlIFc/bwHz2np6Mfe+T6zb3FJ125qUhTykb9G2N3zpXTP6sKpEnH2IK1vrC7ZdZxwU+njE4v22XzqiUe1v019lr4i3zTtXn5Lx6PvRDHrcfZj7TMpCcfh2T8E4L8C8G2Rydn/e4wm+e+JyCcAfB/ALxzjWBEREfcJx1mN//9wdJbsT9/d7kRERNwrTDmCTpCPI+eWV5wwBGnDbw6sjVJSCeGdLS0JtLa6ZtqdXFFz8cHT1jzvdNSMX6VzS99SYwlFS3U6dkExJ6FKptcSJyDI9FrLlX9Coufr9C2FtLmjuuYllZLOC2tWDno6HlcuW3omJ1Py3IMaKbjq6J6CrrPRsG7IHOnlC0fJBWfe0nVWjmpKGmreJtBzNcWamc2GunPL85Y2u3FFr22XxCKvXrlh2q0s6L12DhXmKaqtojLSlRP96NdUrspnjnEprsT2n+nHjI/vohLb5PJ0u9alyhLtywNrOvbvfuQh066k6MhXN7zu/f5z5e4RIcbGR0TMCOJkj4iYEUw9EWZfA17mbfVUrjhaODO+s60m7d6eUvxNZ342G3o5p9etm9CfU7Pq0Qu6els2LCvAiRP9nmUFUjLJ81zN+Mz9ZjbJ9F2es0NcUcRVp2/N0c6emqo3r2pyRLJrzb7Otpr/V69YkY7r19QVWKJV9ff+JbtK/eRfeM9ke27RrhxzwsvQRIj5ZBeKoEtshF5OY5AG3e7v2ii5FolL9MW6PIE8rN6mPh9lx55rlZ6lpba9nw1aLS/4WjKXdFNRxJ+PriN3JYh95viQacbmvn0mljPWDTS7sLOjJnl3T1ftW7kd74fOqrvScwkvb1ej+14OonhFRMTMI072iIgZQZzsEREzgukKTopA0pHPUxfW90mo5ldzxdMiut0lqiypLDUWMqVFZNn6f+xDleRvt1xZ5oIi0lpL1v8DUW8tEsFMXf2yjMruMg0HWLe3KFwEHWX73biptNPmK7YMcY9KUw8H9hjbNzU77K1XX51sDxyNOE/ZfRcef9Ls41pqwWSp2celpvCL1PnAgco0B75oF+FVDXTfxtvXzb6tq3qd2xu0VuNEHdaXlFZM3fur6Ou6S0rPWG/oshFZOMOJonA9N3HHr+lZ4trXIXeZilT6ejm1x3iEnpGc1p06rraCbOkYPHjK0s77td9eveLUOwjxzR4RMSOIkz0iYkYwZd14MgsTmxCRN0kMIji6iuiOJpm+wUVBlUSbNcRGjJVtpfPyE2cn26unzpp2zQXtR+Z08iRTkzOBmtxiC+2iIi30ftf+npaVmmZ9otoAoE8lp7s7arKJK90bSjVBa+cKLFOCTotKIWViaZyNy0rtLa3asTpBZrxQKSvJ7HiUBV+3Kz9NY8J0pusGrl7WZMmXv/OK2XfjktJQ/S29f0++x2r9Lza0j0XXmrE9chNCSlRqy1FonBjkSkgFeicG935MqC1TaknDjkc51PPlviQYRT0mKZv0to95U925l1592+w7NY4e/f61o9/f8c0eETEjiJM9ImJGECd7RMSMYLolmyGoxz67pNb/a5IARLtldcGXV1TejkmRsnZ+UaV+XXWL2mbLc1SWuW3Vc1jXvaqtPxyGpMlONIsE57OTKMX2nj1GSSKQ3Ws2Y624puGz87Rukc/Z8ajZDw2WngmkFZ80tF2/Z6mmHglbFIXd1+2R6hgPY8OKeA65bl1q70UurBuv92Xrpg0RfvUlpQcvX7TjMdyhTLRKn5fHHnrMtFtfPjHZHgztvRiInnunq8dbf8BKJhoaseU05YV9dgvj3wtTkW5qUShtEPtMcIm7tXVt52sr5Kn6+rW7zlffGAmypLHWW0RERJzsEREzgqmLV2Rj7XFx9EOTzHrxwjhkO6Ws9+Y0vK1Vb4/RyClDq6cUV+JMqqqgrLehzXorjSCB2rcu4AolRWcNnVDBkEQpOps2YqzaIzqPMv9qrxlB+u0tL9dAQguctbeza8UOvvO9b022twd232Pv0oy41dPnJtvNORu1JVSaunI0UU1hhQmN6Y1L9ppf//OXtb87zuUZsCtAUWxizdtVMuOv722afQWZ7tvbSuVVYunMxWXNklxI7LWklMHns94ykBY9i1xU9tnksly1q5FdlxS9R+5bltoo0NVFdefe+fA5s2/3xijrLU8j9RYRMfOIkz0iYkYwdTM+HSfCZC65PyMdtyyx3UrJrBKzzyVf0G/XoLBmWp9Md/TV1AulNdWHFJHWH7hoLEpMqElzzSe71KWa4IOuTUDpd/QYezvWfC4pEaamxAkv4Tyg5Jd+zwp9nD6tunOBV2Y79lx8nTduOB27N3SMu33t/8q6jTacX1DzObTsSn1Ccsk5yUrXu04DeZeSl2prnncocnBIQ/DmjjPVSe66kdtnh7X8SqoO/NZ1K/px4dHHJ9st52Km8xT91rD3okmmNleGrf2yPdFBXu55SFVuK3JdBi4acNjVZzWr7DieWh4JeHDZMI/4Zo+ImBHEyR4RMSOIkz0iYkYw3Qi6AFTliHaQxEW4UcncylFqrab6UBxFVLlssLomHfPS7huS71l3lP4Zdm1E14DotWHhhC/JZyqpzLEcKJus24UTSajI3w6FXS/IiQ6qyPWqHZ3SJR39q1evmX0LnLVH0YBuWcHovG+7qLYB9XmH6MAzXUuNPUAufMOJUTZJaDMlP3LBCUIukODn7rYdj1LHUOgAACAASURBVJr87y1aY3iDKDQAuEF++aqjAFv0HMimfm+4a4+xs6jP1cqKjaoMQf1yydxAkuhFQjRo6gQhWS7f++wVUXZFT5+/zqarK7BBZauv2fuejwVT5E5KNotIS0S+KiLfEpHvisg/Hf/9goh8RUReFpHfFU9+RkRE/EjhOGb8AMBHQgjvBfAUgI+KyAcA/DqA3wghPA5gE8An7l03IyIi7hTHqfUWAOzbSfn4XwDwEQB/b/z3zwL4JwB+6zbHQjkcmSm1E3xgzTIuFwQAVcGJ/9plT68NhvrZWfEoh2rqhd3Lk+3+jqWdmG4rXejakCi1stT+Z+I0yMmE279e/azmqLjjNzk4kMLyBkPbTsg8L5zGeZfowQdOabJHdcIKVAxLNc8HQ2sugmidPTKZd9qWXjt9+sxke23J6sKhpYZem6jD1VVbL+AkJaTc3LU0Jes/tKlEUtfp+XdJZ+5k2x6/QS5Q2dOx2bx82bSbJ9O9eNhGPc6tKcWYtt29bunzmJAgS1IeTcdWXpeeHtaaXKjOjnNXrqvQR8fp7/fGiU61D7ckHLc+ezqu4LoB4EsAXgWwFcJEWfEigAeP+n5ERMT9x7EmewihCiE8BeAcgPcDePKwZod9V0SeEZHnReT5ze2tw5pERERMAT8Q9RZC2ALwZQAfALAiIvs2zDkAl474zrMhhKdDCE+vLq8c1iQiImIKuK3PLiInARQhhC0RaQP4axgtzv0hgJ8H8DkAHwfw+duera5Rjn3KqrB+UUU+ZHCiEQn5a1lOPljlw1n1e5WzM/q7Ku4YdjVUsmShBgAV0SImww7OdCHqKiTeZ6ewydL6ViVRb656sQl1FNpuuTWB+YU2fcf6hhtX9dpWV1SIcW3dlkOua6WTytr64oF07wsayNqFFg84BNfRiK1MKcCSymXv+FBXEs4oa3s/BxU9B8RndvbsGsPN60qlnnNa/yzgmLL/HiyturWpz0enY+/ZCr0TMye6kqbZodvBl7cmejY4sRMW9ygHeu5hz17nXof62LNzpBiv69zCZT8Wz34GwGdFJMXIEvi9EMIXReTPAXxORP4XAN8A8JljHCsiIuI+4Tir8X8G4H2H/P01jPz3iIiI/www5Qi6CuVgZJr0O5ZWKIj+CbUrewOi5VK1U4bOrOwRJVM4e6a3p7ROQvRU6mgQDjXLHT2Y55R9R5prVeV03QNv22NkGZv4jh+kL+a5mu5zLpNrcYFKR7ssrNdfVe31Jgl2PPmux027Jummt1x4HUc3sqdRVnZMN68rfSWu/NMZGp90oH286TLsbmxp9N6wsqZpSmMQatKSc9mCeztq3h5YhKLnoKJjuCA2FETb9lykYFWy8IS9ZwmZ6xxJmbiox5TcCR/lVpE7OhyoWzMY+Oeb6FIX3bkflRfuJIIuIiLixwNxskdEzAimbsbXw9HqdzWwK41FV02zsrCRVOVQzZc0VzMlOB2xgjTjar/iSau+rDNXu9+7TGhF1V8AmbvNBiXkOE2xAbkTbiEdgczK0gkQcHJKxt1yd2mOkkwunLexTHtbOo4b1zTi6qGHTpt2J1q6Up9nTpCBosKG5GqkzuPhqMQrb71m9t0koYgza5ox0+naklcDvteJHfGMKpo2SeuNTXoAxlRvN/1quW7zvWA3aXQIkt3u2uSlgvQAOQEKAISqtabk/ohzedh09zJxQq4AR5LWjp2oanqGHZsQJklg0YyPiJh5xMkeETEjiJM9ImJGMF2fva4w7I18ymHX0icDKl88dP48i0Um5Nd5bT2OwBLn/3FmEWryy330GwlaNpo2GmtuXj8zxVE6qpCFHpP8gNOu53JCCNxjpr/SxDrL802icU7YEOTHHnl4sr23RSWe+pbG2dnS8VhZtdeZL1BEHYX5+RJPQhrq/cLu65F++8ZAz9V19z3QtVWO6iz4ftIwelqrRxF1PrpuhyInB1TqOnclm0tTZttGdxqK1ClJmjUYLideuKzOgn1xR7lSDQLWFvXPd4OepZ64Po4fiUi9RURExMkeETErmLoZX4ypl0HXJqB0SBOs6FmzuCITK+HqoM6c48qqiac3yA7ss36cM01B1NtiZvXD56j8TkFiBP3CUiQJ6447CtDI1ZWOQiITLJAJ13JRcuwKhKZ1Bc6cUpGKXaIHAywV1O+rGVhW7jEQNevZdIQvW0QmbOLMR/ZQhl01ravS0lrGi3KuV0KUYIO03lruvvAzMXTuijWFtf+F60dGOoeDvkteYh3BYE1woWMGolILV3MgMC3snhemElm4peHcvFZbx2O3Y+9FOQkJjGZ8RMTMI072iIgZQZzsEREzgun67FWF/jhDabBltcqHJK43cP4Oh6My88FiAeMzTLYSl8nF/t+AfE3JHZVClFe3b33qJXJ7G1Q2OW9asUWuOVc5/4zXCHym2JDEKVmYMojz+yvOzLPHWFpQ3zOj1K5u162D8PoGLLiksHCpa/ix0s9Z7mhEyiLjcsXtpu3v8orSfBt7lk5i8YqkUqps6MJ2mRrLnSKIHLGO016wYbWBHiwv0tHrKX03P3AluMGCI3RMR70ltO4USvtM8DqACK2DiF1naZFwS+LqLsh+6LhXROE+HLknIiLixwpxskdEzAimasZXVYnd7VFkVc+b8aSvVZZOr50soop+n8ramlusC8dljQFLwSycVnqqrO0QNDLSDw9Wg3y3q+b63ByV6nU6cFWitGLt3QkqPz234DO09HPR5/LNzhXg44krd9TQY5SUNda3TBMSoiIz506YLD46We1LGtG1+WMYf6sk92rO0mYLi2rG+wzBAXWa6TUvFrJJ5au6Tnu+JDeKxSsazp3gEtyhss9VZ0817ua7Vn8/p1Jlge4tXzMA5Nzn2otjUB/JdfHZfZyduEACJgCQjJ93776aNkfuiYiI+LFCnOwRETOCqZrxdajRH69m9vrW3Cpo9blyyQYlrXg2qQqoL7s06KnZV3TsqmnJ2tLUbnHeSiyfffiJyfbq+jvcMcjsJrM1z5zpmCizUBY28SOjCKnM6d9lOSVLzOl41AN7/GFfI9IGQ2sSHmW2+qSKnCLGfBVaNuM56URcWCIpZiM4UbecvldRhV4fgUZ5R8icad3kqqgkSlHs2Gve3tKkm+sk2AEAgZJOOFrPW7upYTysz7O3S2Z854TZN89RilT+SZwZb0p9uei9ckjy0RQBWFdeUp2Tow4f76ON+Phmj4iYGcTJHhExI4iTPSJiRjBVn11AEWSOrgJpowdHvXFk0gqVIQ5iu3/1spY+6rr6T+yz9vfUZ1p7eMm0u/DouybbJ04+avZt76lft0uihN2+FVEE6csXQ0uRZKI+dcP5wEICEBwg5UtYc4bgjWu29PDONSptRdFjzXlL83E2W+azzShDjktZ5U7ooyIPsXR0GPuoQsKgwV1zq639WlxaNPtubimFWZkMO3uMPq3BXNu4ZvYtLWofW231qQtXSjuktL6R2Wvp0/3t7NnyVdm89jnNyad2kY0VZThKefQ6C4to+JoDvA4y17L3M0tHz1zq0z0Jx36zj8s2f0NEvjj+fEFEviIiL4vI74pI43bHiIiIuH/4Qcz4XwbwAn3+dQC/EUJ4HMAmgE/czY5FRETcXRzLjBeRcwD+JoD/FcB/JyOu5iMA/t64yWcB/BMAv3Wr4wRomZramxs5GQbOwp9bUnps8cSZyfb2nk3uuEmJK5tO+7vZUnOaI78ktaZj3lKzvk7c8JAZ1WiRzlzDReEVlHTTd7r0REO1c7uvkegYJDUlPThttuVVpX8WV2xE1/yiRv1tXHlzsr27ac3botCxW3SVT1PSaE8qNp+9WanX7VXVqkDVaklgo0yti5ZTBODCsu1HvaGlora2lX5caVjXqCYxkps3r8OC6VLdFDf2KamFZC45isuMeTM+J0GTJnWrldk+cpRcKOyzWZlqxEcnKKVcmsw9m2E8rp5GZRz3zf6bAH4Vqoy3DmAraG3fiwAePOyLERERPxq47WQXkb8FYCOE8HX+8yFND82tE5FnROR5EXl+1xXMi4iImB6OY8Z/CMDfFpGfA9ACsITRm35FRLLx2/0cgEuHfTmE8CyAZwHgwgOrRyfbRkRE3FMcpz77pwF8GgBE5MMA/nEI4e+LyL8E8PMAPgfg4wA+f/tjAWU5MgrqYLO1klx9nMxprZ95+J2T7dbS2mT7lUsvmXavv61+abdjvcgFEmlsEZWXNmxmW5KrD18GOzw1hVRyplvD+expk7TtvagD+X8+hDUlKlE4w8yF1eZ0vvWWzSJrE5U1R9tvu3pumzfVH+4PnBoEix5SFl3mBBCFDEPxtfWoz6yPXyT2vpQ0PvNLVgRkpa3PRG9Dw47bB5ZS9Fw7Tpc+aepzli3QWo0TfzChv+6egeqqDXtWKHWwp+eTmnzqtj0+SGCjKlzWmxGcJHET1w0jKuJem/sCIT5smXEnQTWfxGix7hWMfPjP3MGxIiIi7jF+oKCaEMKXAXx5vP0agPff/S5FRETcC0w1gi6RBI1sRK/0E5uY32ipCZfP2ai2B89rVNtuobbNxvZ3TLu3byil0XKlm9Jazd2kpvK/6bxpV1OmlS/nnHJWVl9NsZ4zy1pkWrdz6yZUQz2+uJLNbIBVJZcEcuYzmfguqA1toilPG6rQuk3rm+oObVy1yy0c7TWkDMTgyhCn5BrVzmqtyS5OqL91sA0rMvfnF+w9O3lCacXuplJvy217z/KGXlvlbNWhiQbkcbT9qGkcB040gjP/qr414/ubOnZtpibF1QQg74Wz3ABgWKhrxyWwnFaIGSuvv5iOr0dukfcWY+MjImYEcbJHRMwIpmrGQxJk+chcb9mFV8wvaTXSM+cfN/tWT5+fbO9eUb2x7Z41WXYHejm7LtGhKNXUay3SyV1I/w7JGbdqZz5nJKBAUU9dV66KmYZ2yw5xkvGFWxs8GClsSqo4uCw72SyHflmWVvQp0mxp7aRp1qKIwmbb3oy9XTVV+z0yMV35pyHJJVcueSn1/sV+91x3S7qWxEW1La2pCzS3pNqA3lTlfKjEaeElRHlw0GYQl4REO310J59NnL+SUmScDPXZEcd+lCXfMxtBNyj0e0N6rnw/2L0d7lqdvHoiOx3N+IiImUec7BERM4I42SMiZgTTFa8QQZqN/Nm5eXvqxeV12raifmmulEySq7/T6Vv/qTugEj7ON+xT2eC1E7qz6Si6zU0VhjjtBAIK8l+TTPufuvJMrOMwcH1sNTn1ypdK5ugp3S6dr8x+b+38fi5NzWqOvh2IullctqKbCX2v1VJacejELXdpfaNwfWSBiSFHjwXbD762AwKL5PcmFLG4t7tr2g0L9e3TpqXlGiRYkTaY1vKlrEj/3XFezBZWLvNvSBl3LKLhebOSxoC/AwAViVnUho51fCav6bh1nElG3C0UJ+ObPSJiRhAne0TEjGDK1BuwXyEna9iIrmabNMIb1tTrkflYkE3Vc2blgKt5ZvbStrZVR2xzm6KgfAIHUR97e1YIoSQN8ppoOZ960GgolVW6hB+hJJZ9l0a7QscnffXKRa4ZS9JRSFxBls1RxyKipHHs9+04skmekZ5e3rBuDZeDqh0lNezrMfo90rJP3TWznP/ARZaR9jpX2+0Xnnai+960x2czPqTaj8RXpKVxrJ3mex2OphiHVHG4m2iUH5vtgKUtffkq1p0rq6M16Nisl8Ttu0X11n3EN3tExIwgTvaIiBlBnOwRETOC6frsCJNsoNyFkWYk4BhcxtAeZRoVRM+0XPlfrphrKC4AfWra66n/vrttS0evLrNPbX1Ijl4cFNrHlsvCKshfRWpDUQPVWPM1io1bHY4WMTC0kXfVhOlHykpzfj+LHHgahz8XpGnuj5FTaOrCvB2DHqV5FQP1sYeVl6bUcw2dEGNJvnOaUX9Te9FcI87XiwvUtmIqy4WzppztWPt1HPqe8415rYK16CuXOcfX6X12/szn9seoac0owO0L++f2dJ0ivtkjImYEcbJHRMwIpmzG16hlZIYnjoJJUzVRysqazwWbehRttHZywbRbWNTL8SWN1k+ottzCPJdnstFY3Y6aga221ZRHSplLAzI5MxdBR/RJkjmKp9CIvdSVwApkgnEGXHCmmY3+8tpvRM9wySQnGsHUk7kWAAVRYEMywStPSdHxfUZcoM85UYxJ356L3RXWzAOATk2ltZc0S6/Yc9GACWWeOUqK6cFKaGzsEZCSQEVWOzqTrtNrvCXmXlA7z5rxCV3Zav4cyIwP3ownLbwD4hiyPy/ujQZdRETEf0aIkz0iYkYwVTM+QFBUI3vGFVk1UUR9p/NVZmoeDUgoYmXJrsbPz5FwgzNnHjh3Vr/XJvM/WJELrpC6tmp/CwuK3Op3tB/iVlcbmSaWZC6CDpToILUdfpY35pVXcavDMMkjziSs6XrYDPS6apxwEew+IbOyJrepGvjIL+1HUTg9vfrwPvrINfZkGk6qOl1U032eVtmTsmPaJeQCFqV1AZtB2ZCUjl85U5qTfPx9SW5RGVXYXZSjV+0tvI1Pprsx6Z37xs+EO/6ErYiJMBEREXGyR0TMCOJkj4iYEUzVZ6/rMBGYSBxd1ZonWsRRQe1co7NyEvVbcb1fJsHC7V3ru62RQMPaklJqlRNMYGGEqrBRYYOBriWUQ/XfS5d51kwo06q2pXtZ2SLxPpnROKd9PhqL6ZnSrjmwEEIgPXvfDiyUWNoxEPpeQhrycO0CZXbVzmevaVGG3cg8dUKMFUeFOXqQIvRaRN/JKavFHyjKbzCwVGpOgiZtEuD0awec2SY+k5DotuAoTI6uY3/bu/l8zNqtF5j7Tt9LHDXLZbwrt+ilfTx6reC49dnfALCL0UpCGUJ4WkTWAPwugPMA3gDwd0IIm0cdIyIi4v7iBzHj/2oI4akQwtPjz58C8FwI4XEAz40/R0RE/IjiTsz4jwH48Hj7sxjVgPvkLb8hQDqu4tnp2GqbS1TBM2/Y36B+R+mwdqomz9q8jbh6cF1LGm1ds0bG5lU9BoZkRg2tEMKFh09Ntne3ts2+BGQWk2hBJfYYZUPdkDx1lBRFe4XE9t+YYByCVTt6jai3UDnznMxpNm/rwraryYyvnI45uygVbdfOFQjlLdyJAUcDUvVUV/E2Y7rRm8iB3Ro9xlzLmdkkVJK5iMWiIIq0T2a205evK0qmgUM4OrkkMN1G5r4LKERK+vW1u581CSaabUerssvgxUImn2/B+B33zR4A/IGIfF1Enhn/7XQI4TIAjP8/deS3IyIi7juO+2b/UAjhkoicAvAlEfnecU8w/nF4BgDWl+Zu0zoiIuJe4Vhv9hDCpfH/GwB+H6NSzVdF5AwAjP/fOOK7z4YQng4hPL0w3zqsSURExBRw2ze7iMwDSEIIu+PtnwXwPwP4AoCPA/i18f+fv92xEgH29QA3N63PfvMG0QxideOrUikvrpXWdOGV585qPbO33n7b7Lt08fuT7bp4YLKdYd2029tR/3V9yVJvzYZSaiWFmA6cYGN7Uf2p3P++tagccuqEE8kHrjl804kXoiAxSie+WDHdRj5f5QUZTHaV90n5M1FSjhpLaV0h884iucQV+aG+H0xRNXOXBciPBGvlO2qMhTAbntoj2rLksfL1kGul9jy9xn08UD7bKo4ctcMIa/rxPsoX98KXoWR/Hnbf7fUmj2XGnwbw+zLqfAbg/w4h/DsR+RqA3xORTwD4PoBfOMaxIiIi7hNuO9lDCK8BeO8hf78B4KfvRaciIiLuPqZc/gloNkbmjc9w2rxxdbLtTbG8oQt7QrrdxcDSWqvLms125pQtaXTt6kuT7Rs31MZk0xwArrbV7l5s2X0n19WsT0BRcs4kzEkMz2vDJ2SCHojGYq14jpqrLDUmZI6WTju/IootUGab1zEvyBUYOLNyQMcoTPSeo9eo7FXIvHnO1BZHj/msNzq3Czvj8k9sFWdNS1mm1H8fobefZQkABbledWqpt6rgKDmvH0fZlC7bjLvstQIZwtd5IPqNzXi2970rQH0OXr8wnWwdhRgbHxExI4iTPSJiRhAne0TEjGC6SjV1jV5n5H+KKz7W21M/9Ep5xexbP3F6sp02SLWma/3QjJymU2snzb7Vpct6Lgqb3N6y/vBiW33g7RXro65StlyDOLXMrT8ErgNXuOyqkqkVpx9Ooa7lgMNerTKLlJSZ5zLRCjomh7OWBzTZ+dps/2v6bOq5+UwxouIquNBO8JqA/t0LNqaUqejr84HFI2k9o9myfGYgHzhxQqONQEKStM7iNCUxYIFPx3QmtDYhiRO7PAJ+PQZmTD0NSufmZEdfoI/ezYnYtaD9oZNbLBzEN3tExIwgTvaIiBnBVM34sqxw4/q+CWrNLU4+u3nNlkre3VazZ25hZbJdue6XtZpY7YaNfjt75txk+9JlzYjr7FnzttvVz4OBF2Sg30Y6dfDqmWSKpc5EFhMt5bPZSFCQRCPKoRXikFojCmsnvsGZUlzquazstVT0+aCwIZdiJqqwtpQXU44Ca96yOZ2TGVy6a2ZzN7h9nJjGQXO+9JGQIGl9oB/6OSUTV2pn7lP5sdIxb2Z8/OuRI/uMyIVtxll7wZ3b6O8bM96dygTo2Y5kyb5rc/T7O77ZIyJmBHGyR0TMCKZqxhdFwLWNkZnsS9v0umqO7u3aVfCbN65NtucWdF9zfsm0k5Qi3hJ7aetrmvzS6elv3NXrNiFna1tN5EuX7G/hXK7m6OqiRvX5arLzi7pqn7qlXSGxidrZi6zpFsg8D86MrwbqhgSne18VvAJPFUFLaxPy58qLUrCuGi8cBzseQpr4XiadRR0SirzL/OuF27mosIRM8owTUJwZbFag3fFNdCP3362Wp3K4iwYAFd0XOXB8Fqw4RjYKAHEJP+z22cX0oyvvwq3GH0jsOQTxzR4RMSOIkz0iYkYQJ3tExIxgyj57hctXx9SbDzAid6QsLcVTkH/ZoZK/+a7LNmuSjrn7HesPWdNbj7920opXlP29yfaN61Z8JyXKq7uu6wWnH7DReitruq8uLbVXDSkLq++FJygri7jIAdWfA4Aw1H54n50FMIZ0PKbhAEvr1H4fZcRxnTlxPrsVZHBReOwqky+buSg5DkhLXPQX01USWLDR+eyUweYpQPbvbXai02TnS0v9AgRnKvqMNY7yY+FI1w0eR3edPqJu0s5rz1PJ8ETcHBnGrLeIiIgx4mSPiJgRTDeCrgq4sTWilDxNkZL5lTpTryTtLaNh1rNmMJs5wf2OFSTkPSTarxAXLkXlgCWztFkaNAElFHu0x0axzS1oosbCYtvsW0lUVKMaWEqtv6fmOeu1V909067uHq3lXpPwAkfNlV6DnExObz6D3CYuUZW4JBC+g6WjsoSOLyZJxpWpDrd433D0HvXR31sYCtBSUmzxV4bi8jQil3Hy5afJnfACG9SvWo4uqcymuzfjWdiCv3WLStFGBAUAwjih6FYCGvHNHhExI4iTPSJiRhAne0TEjGCqPjsgKGUUWlo6umHADlVh97F/xTW0/DEC+c7i4jKD6KWyOEPhzsXaB7WvB0bn6xNttrXlQm5v3JhsL87b7Duuueapt/6e1parBrRv6Oq59WjNoW+pvZqoOKG6Zwd9SMqIc8ITHPsq5EWKD8k0frm7F+SLyy1ENkuT5mUPn+W0XpA1j2xn6KYD8ay+7f7f3doBi1ccEJ5g9Q13ZnKSOdPvoDAl++y2j0Yrvua1A5/2RudNXLjvvrBp9NkjIiLiZI+ImBFMV4MOwIRFS/yp1UbxohFJSiYQ6YJXpTUdCzbrHbXHJm1KFNLQBS81yNyvHF3FH5kxKvq23eYNzUrLXVnmzrZSe7UrlWzNeKLbhvZayj5RkUOXVUe6bSmd2su7GTn71FGMNFY5ZWgFH+kl4ch9rJ9WCtGPcni02OhwzkampglnD3oKkKkr72nwtuG1/Mn1D6nLKLMRez4TjcU3eKxcpB27Q66PJmmP+uUjBe25HdU5HoNb5b4d680uIisi8q9E5Hsi8oKIfFBE1kTkSyLy8vj/1dsfKSIi4n7huGb8/wbg34UQ3oVRKagXAHwKwHMhhMcBPDf+HBER8SOK41RxXQLwVwD81wAQRpkXQxH5GIAPj5t9FsCXAXzyVseqQ0B3MFoxb2RW8CHNKQrKmeAlmesh5VVka8oMyZT0C5m1W9DeR55aWeIGmbBZar+UcIQUrbzWlR3GXZKnDqVNYtnb1lV2qaxJW3Y1Qo8TYYITnigKtc97AydeQRfKFY5ErKmekG4b668BQHuOtPzm9L64SllIaQxSV04ppPq9knWbXYQbm61p6ozQIyrBepckkL1fOU0+IXfR9NE/IByh53ZxtJq3rK14Ba+qO7eGns3EraQbPUDcAlxCyrXcLxcWbnGE47zZHwFwDcD/JSLfEJH/c1y6+XQI4TIAjP8/dYxjRURE3CccZ7JnAH4CwG+FEN4HoIMfwGQXkWdE5HkReb5wC14RERHTw3Em+0UAF0MIXxl//lcYTf6rInIGAMb/bxz25RDCsyGEp0MIT+fplGN4IiIiJjhOffYrIvKWiDwRQngRo5rsfz7+93EAvzb+//O3PVsAwph7GzrfKmUf5wB9ohYBZ8D5ckTs/3mChyOk6pJL8Vj/KWsqTdRu24y1eSo9NZfr8RpO7ICpuK3ertnXa6p/lnl6hqk4KtdUOz6poHWG7tDewooisPiaS6emUBtey/r9rZb6tvNaBRuNliulTe53u2199iaVVZZMxTl9eesG3eyDPjvdM/JX6wOqDvzB3vlMOJvyaPEKg8oeX4iOhVtnCcJrCXrNB3x2yrT0tFxCJb4D+P75SD5ec/Da82H/AEfiuK/afwjgd0SkAeA1AP8NRlbB74nIJwB8H8AvHPNYERER9wHHmuwhhG8CePqQXT99d7sTERFxrzB9J3psPdXODCkHg0Maj2Dkson78AsOnIiQUkgEGwAABS5JREFU3iKLX8g8rEqbjAKqulpkNvqtR/1IKISuSOy5ONirdrRZr6/X2XA2l5BmHCiKsHKXsgV1DfYKX7qJ6MfAZrxdHC25netHRvr4rW39XuYoOqbA2m27b6Gt32vN6bU0G/aRa7f1c7u2rkCDXCVOLGk7mi+pbhVZRpQX6dj5RBV+xrxIB99e74awi3UrgQqOhqsqT8s5AZXJMY7+g0+SkYlbcmfUW0RExI8B4mSPiJgRxMkeETEjmHrWWzX2LVInDJETneJdFU7oN8KJ3j0hP8aH3B7syQiJ03Xv90m7vbTD02GNBAp/ZHoHsP33ZYhzCt9spPa31og7GnVE265L3eqUjoKh62Y/tBi4Etk8Ps5HRZ+uYJd8XnfP2KfMGpa+a2fk9+cqpLmwYGNul5dInHPBjvfCHPnztF4Q3GPbalJI7C2y2azOvdfR57LPnjajuniVD3XlfVSr74AABvvb9gk3jzQLghygoPmYPnUuP/zvhPhmj4iYEcTJHhExIxAfzXNPTyZyDcCbAE4AuD61Ex+OH4U+ALEfHrEfFj9oP94RQjh52I6pTvbJSUWeDyEcFqQzU32I/Yj9mGY/ohkfETEjiJM9ImJGcL8m+7P36byMH4U+ALEfHrEfFnetH/fFZ4+IiJg+ohkfETEjmOpkF5GPisiLIvKKiExNjVZEfltENkTkO/S3qUthi8hDIvKHYznu74rIL9+PvohIS0S+KiLfGvfjn47/fkFEvjLux++O9QvuOUQkHesbfvF+9UNE3hCRb4vIN0Xk+fHf7sczcs9k26c22UUkBfC/A/gbAN4N4BdF5N1TOv0/B/BR97f7IYVdAvhHIYQnAXwAwC+Nx2DafRkA+EgI4b0AngLwURH5AIBfB/Ab435sAvjEPe7HPn4ZI3nyfdyvfvzVEMJTRHXdj2fk3sm2hxCm8g/ABwH8e/r8aQCfnuL5zwP4Dn1+EcCZ8fYZAC9Oqy/Uh88D+Jn72RcAcwD+E4CfxCh4Izvsft3D858bP8AfAfBFjIK770c/3gBwwv1tqvcFwBKA1zFeS7vb/ZimGf8ggLfo88Xx3+4X7qsUtoicB/A+AF+5H30Zm87fxEgo9EsAXgWwFcJEemNa9+c3AfwqVHVi/T71IwD4AxH5uog8M/7btO/LPZVtn+ZkPywdZyapABFZAPCvAfxKCGHndu3vBUIIVQjhKYzerO8H8ORhze5lH0TkbwHYCCF8nf887X6M8aEQwk9g5Gb+koj8lSmc0+OOZNtvh2lO9osAHqLP5wBcmuL5PY4lhX23ISI5RhP9d0II/+Z+9gUAQghbGFXz+QCAFVEp1Wncnw8B+Nsi8gaAz2Fkyv/mfegHQgiXxv9vAPh9jH4Ap31f7ki2/XaY5mT/GoDHxyutDQB/F8AXpnh+jy9gJIENHFcK+w4hI2GyzwB4IYTwz+5XX0TkpIisjLfbAP4aRgtBfwjg56fVjxDCp0MI50II5zF6Hv7fEMLfn3Y/RGReRBb3twH8LIDvYMr3JYRwBcBbIvLE+E/7su13px/3euHDLTT8HICXMPIP/4cpnvdfALgMoMDo1/MTGPmGzwF4efz/2hT68VMYmaR/BuCb438/N+2+APhLAL4x7sd3APxP478/AuCrAF4B8C8BNKd4jz4M4Iv3ox/j831r/O+7+8/mfXpGngLw/Pje/D8AVu9WP2IEXUTEjCBG0EVEzAjiZI+ImBHEyR4RMSOIkz0iYkYQJ3tExIwgTvaIiBlBnOwRETOCONkjImYE/z+Awe+CLIco4AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_load,test_load=batchfy(batch_size=100)\n",
    "show_img=iter(train_load)\n",
    "for batch_i, (real_images, gender,glasses) in enumerate(train_load):\n",
    "    debug=real_images[0]\n",
    "    plt.imshow((debug.numpy().transpose((1, 2, 0))*0.5)+0.5)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "phi(\n",
       "  (fc1): Linear(in_features=99, out_features=1000, bias=True)\n",
       "  (fc2): Linear(in_features=1000, out_features=99, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phi=transformNet.phi()\n",
    "phi.to(device)\n",
    "\n",
    "invphi=transformNet.phi(inv=True)\n",
    "invphi.to(device)\n",
    "\n",
    "#Transform=transformNet.full_phi(phi,invphi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_phi = optim.Adam(phi.parameters(), lr=0.0001, betas=(0.9, 0.999))\n",
    "opt_invphi = optim.Adam(invphi.parameters(), lr=0.001, betas=(0.9, 0.999))\n",
    "#criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "params = [phi.parameters(), invphi.parameters()]\n",
    "\n",
    "opt_transform=optim.Adam(itertools.chain(*params),lr=0.001,betas=(0.9,0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TripleletLoss(batch,targetAttribute):\n",
    "    def triplet(value, positive, negative, margin=0.2) : \n",
    "        d = nn.PairwiseDistance(p=2)\n",
    "        distance = d(value, positive) - d(value, negative) + margin \n",
    "        loss = torch.mean(torch.max(distance, torch.zeros_like(distance))) \n",
    "        return loss\n",
    "    \n",
    "    def findtriplet(src,attribute):\n",
    "        timeout_start = time.time()\n",
    "        index_list=np.arange(len(attribute)).tolist()\n",
    "        rand=random.sample(index_list,len(attribute))\n",
    "        for i,posindex in enumerate(rand):\n",
    "            if attribute[src]==attribute[posindex]:\n",
    "                if src != posindex:\n",
    "                        break      \n",
    "            if i==len(attribute)-1:\n",
    "                posindex=src            \n",
    "        rand=random.sample(index_list,len(attribute))                \n",
    "        for i,negindex in enumerate(rand):\n",
    "            if(attribute[src] !=attribute[negindex]):\n",
    "                break   \n",
    "            if i==len(attribute)-1:\n",
    "                negindex=src\n",
    "                \n",
    "        return posindex,negindex\n",
    "    loss=0\n",
    "    pos_pair=None\n",
    "    for i,value in enumerate(batch):\n",
    "        posindex,negindex=findtriplet(i,targetAttribute)\n",
    "\n",
    "        if not i:\n",
    "\n",
    "            pos_pair=batch[posindex].unsqueeze(0)\n",
    "            neg_pair=batch[negindex].unsqueeze(0)\n",
    "        else:\n",
    "            pos_pair=torch.cat((pos_pair,batch[posindex].unsqueeze(0)),0)\n",
    "            neg_pair=torch.cat((neg_pair,batch[negindex].unsqueeze(0)),0)\n",
    "\n",
    "\n",
    "    return triplet(batch,pos_pair,neg_pair)\n",
    "\n",
    "def reconstruction_loss(z,z_tilde,optimizer):\n",
    "    loss = nn.L1Loss()\n",
    "    optimizer.zero_grad()\n",
    "    error_recons=loss(z,z_tilde)\n",
    "    error_recons.backward(retain_graph=True)\n",
    "    optimizer.step()\n",
    "    return error_recons\n",
    "\n",
    "def concat(z_list):\n",
    "    return torch.cat((z_list[0],z_list[1],z_list[2]),1)\n",
    "\n",
    "def cyclic_loss(z1,z2,z3,true_glasses,true_gender,opt_transform):\n",
    "    batch_size=z1.size(0)\n",
    "    swapped_pos=torch.randperm(batch_size)   \n",
    "    z1_hat = z1[swapped_pos]   #Permutation\n",
    "    true_glasses=true_glasses[swapped_pos]  \n",
    "    swapped_pos=torch.randperm(batch_size)\n",
    "    true_gender=true_glasses[swapped_pos]\n",
    "    z2_hat=z2[swapped_pos]\n",
    "    swapped_pos=torch.randperm(batch_size)\n",
    "    z3_hat=z3[swapped_pos]\n",
    "    true_gender=true_glasses[true_glasses]\n",
    "    z_aster=torch.cat((z1_hat,z2_hat,z3),1)\n",
    "    recontructed_z_aster=concat(phi(Encoder(Decoder(invphi(z_aster)))))\n",
    "    \n",
    "\n",
    "    \n",
    "    #Cycle_Consistency,Loss                 \n",
    "    opt_transform.zero_grad()\n",
    "    loss = nn.MSELoss()                                                     \n",
    "    consistency_loss = loss(z_aster,recontructed_z_aster)\n",
    "    consistency_loss.backward(retain_graph=True)\n",
    "    opt_transform.step()\n",
    "    \n",
    "    \n",
    "    #attr_cycle_augmentation_loss\n",
    "    opt_transform.zero_grad()\n",
    "    augmentation_loss =TripleletLoss(z1_hat,true_glasses) + TripleletLoss(z2_hat,true_gender)\n",
    "    augmentation_loss.backward()\n",
    "    opt_transform.step()\n",
    " \n",
    "    return consistency_loss +augmentation_loss       \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(Encoder,phi,invphi,train_load,num_epochs=40):\n",
    "    loss_matrix=None\n",
    "    first=True\n",
    "    t_start = time.time()\n",
    "    Encoder.eval()\n",
    "    Decoder.eval()\n",
    "    phi.train()\n",
    "    invphi.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"Epoch:\", epoch)\n",
    "        for batch_i, (real_images, gender,glasses) in enumerate(train_load):\n",
    "            batch_size = real_images.size(0)\n",
    "            real_images=real_images.to(device,dtype=torch.float)\n",
    "            latent_vector=Encoder(real_images).detach()\n",
    "            glass_vector,gender_vector,remain=phi(latent_vector)\n",
    "            \n",
    "            #Reconstruction Loss\n",
    "            z_tilde=invphi(torch.cat((glass_vector,gender_vector,remain),1))\n",
    "            loss_reconstruction=reconstruction_loss(latent_vector,z_tilde,opt_transform)\n",
    "            \n",
    "            \n",
    "            #Task Loss\n",
    "            opt_phi.zero_grad()       \n",
    "            loss=TripleletLoss(glass_vector,glasses) +    TripleletLoss(gender_vector,gender)  \n",
    "            loss.backward(retain_graph=True)\n",
    "            opt_phi.step()\n",
    "            \n",
    "            #glass_vector=glass_vector.detach()\n",
    "           # gender_vector=gender_vector.detach()\n",
    "           # remain=remain.detach()\n",
    "\n",
    "            \n",
    "            #Cyclic Loss\n",
    "            loss_cycle=cyclic_loss(glass_vector,gender_vector,remain,glasses,gender,opt_transform)\n",
    "            \n",
    "            \n",
    "            if (batch_i) % 300 == 0:\n",
    "                print(\"Batch: \", batch_i)\n",
    "                print(\"Task Loss: \", loss.item())\n",
    "                print(\"Reconstruction Loss: \",loss_reconstruction.item())\n",
    "                print(\"Cyclic Loss: \",loss_cycle.item())\n",
    "                if first:\n",
    "                    loss_matrix=np.array((loss.item(),loss_reconstruction.item(),loss_cycle.item()))\n",
    "                    first=False\n",
    "                else:\n",
    "                    loss_matrix=np.vstack((loss_matrix,np.array((loss.item(),loss_reconstruction.item(),loss_cycle.item()))))\n",
    "        t_end = time.time()\n",
    "        duration_avg = (t_end - t_start) / (epoch + 1.0)\n",
    "        print(\"Elapsed Time: \",duration_avg)\n",
    "        torch.save(phi,'Phi.h')\n",
    "        torch.save(invphi,'invphi.h')\n",
    "    return loss_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Batch:  0\n",
      "Task Loss:  0.41485169529914856\n",
      "Reconstruction Loss:  0.4043228328227997\n",
      "Cyclic Loss:  1.5709236860275269\n",
      "Batch:  300\n",
      "Task Loss:  0.32545140385627747\n",
      "Reconstruction Loss:  0.10201364755630493\n",
      "Cyclic Loss:  0.5533437132835388\n",
      "Batch:  600\n",
      "Task Loss:  0.30165576934814453\n",
      "Reconstruction Loss:  0.10666044056415558\n",
      "Cyclic Loss:  0.43101686239242554\n",
      "Batch:  900\n",
      "Task Loss:  0.22351883351802826\n",
      "Reconstruction Loss:  0.10000026971101761\n",
      "Cyclic Loss:  0.3561117649078369\n",
      "Batch:  1200\n",
      "Task Loss:  0.3101048171520233\n",
      "Reconstruction Loss:  0.10411772131919861\n",
      "Cyclic Loss:  0.4668482840061188\n",
      "Batch:  1500\n",
      "Task Loss:  0.29572728276252747\n",
      "Reconstruction Loss:  0.10546872764825821\n",
      "Cyclic Loss:  0.349165141582489\n",
      "Elapsed Time:  1570.3096861839294\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/torch/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type phi. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/conda/envs/torch/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  0\n",
      "Task Loss:  0.2934541702270508\n",
      "Reconstruction Loss:  0.10784789174795151\n",
      "Cyclic Loss:  0.46450483798980713\n",
      "Batch:  300\n",
      "Task Loss:  0.23126842081546783\n",
      "Reconstruction Loss:  0.09972812235355377\n",
      "Cyclic Loss:  0.31033873558044434\n",
      "Batch:  600\n",
      "Task Loss:  0.29877969622612\n",
      "Reconstruction Loss:  0.09143738448619843\n",
      "Cyclic Loss:  0.3066519498825073\n",
      "Batch:  900\n",
      "Task Loss:  0.27809929847717285\n",
      "Reconstruction Loss:  0.09516167640686035\n",
      "Cyclic Loss:  0.35675376653671265\n",
      "Batch:  1200\n",
      "Task Loss:  0.26769736409187317\n",
      "Reconstruction Loss:  0.10073316842317581\n",
      "Cyclic Loss:  0.42011886835098267\n",
      "Batch:  1500\n",
      "Task Loss:  0.29206162691116333\n",
      "Reconstruction Loss:  0.09946095943450928\n",
      "Cyclic Loss:  0.24799978733062744\n",
      "Elapsed Time:  1569.5283200740814\n",
      "Epoch: 2\n",
      "Batch:  0\n",
      "Task Loss:  0.2703222930431366\n",
      "Reconstruction Loss:  0.0904562696814537\n",
      "Cyclic Loss:  0.31055641174316406\n",
      "Batch:  300\n",
      "Task Loss:  0.2664741575717926\n",
      "Reconstruction Loss:  0.08968904614448547\n",
      "Cyclic Loss:  0.33835259079933167\n",
      "Batch:  600\n",
      "Task Loss:  0.26454028487205505\n",
      "Reconstruction Loss:  0.11322079598903656\n",
      "Cyclic Loss:  0.5295050144195557\n",
      "Batch:  900\n",
      "Task Loss:  0.21743862330913544\n",
      "Reconstruction Loss:  0.09974829107522964\n",
      "Cyclic Loss:  0.43126049637794495\n",
      "Batch:  1200\n",
      "Task Loss:  0.24467605352401733\n",
      "Reconstruction Loss:  0.09193921834230423\n",
      "Cyclic Loss:  0.2610914707183838\n",
      "Batch:  1500\n",
      "Task Loss:  0.2418588399887085\n",
      "Reconstruction Loss:  0.09427006542682648\n",
      "Cyclic Loss:  0.339705228805542\n",
      "Elapsed Time:  1576.4744562307994\n",
      "Epoch: 3\n",
      "Batch:  0\n",
      "Task Loss:  0.3236810564994812\n",
      "Reconstruction Loss:  0.08453822880983353\n",
      "Cyclic Loss:  0.3274063766002655\n",
      "Batch:  300\n",
      "Task Loss:  0.23834745585918427\n",
      "Reconstruction Loss:  0.08753841370344162\n",
      "Cyclic Loss:  0.2965394854545593\n",
      "Batch:  600\n",
      "Task Loss:  0.2471085637807846\n",
      "Reconstruction Loss:  0.09782013297080994\n",
      "Cyclic Loss:  0.38341212272644043\n",
      "Batch:  900\n",
      "Task Loss:  0.26681140065193176\n",
      "Reconstruction Loss:  0.09172187000513077\n",
      "Cyclic Loss:  0.34337252378463745\n",
      "Batch:  1200\n",
      "Task Loss:  0.27790942788124084\n",
      "Reconstruction Loss:  0.08707629889249802\n",
      "Cyclic Loss:  0.31561020016670227\n",
      "Batch:  1500\n",
      "Task Loss:  0.4012511074542999\n",
      "Reconstruction Loss:  0.1608409434556961\n",
      "Cyclic Loss:  0.9621202349662781\n",
      "Elapsed Time:  1578.2365495562553\n",
      "Epoch: 4\n",
      "Batch:  0\n",
      "Task Loss:  0.23541998863220215\n",
      "Reconstruction Loss:  0.08466091752052307\n",
      "Cyclic Loss:  0.26862165331840515\n",
      "Batch:  300\n",
      "Task Loss:  0.35048753023147583\n",
      "Reconstruction Loss:  0.11812318116426468\n",
      "Cyclic Loss:  0.5745354294776917\n",
      "Batch:  600\n",
      "Task Loss:  0.29838764667510986\n",
      "Reconstruction Loss:  0.08857832103967667\n",
      "Cyclic Loss:  0.34937772154808044\n",
      "Batch:  900\n",
      "Task Loss:  0.27876636385917664\n",
      "Reconstruction Loss:  0.08690991997718811\n",
      "Cyclic Loss:  0.28952041268348694\n",
      "Batch:  1200\n",
      "Task Loss:  0.27566248178482056\n",
      "Reconstruction Loss:  0.08816554397344589\n",
      "Cyclic Loss:  0.3400076627731323\n",
      "Batch:  1500\n",
      "Task Loss:  0.3225793242454529\n",
      "Reconstruction Loss:  0.08741609752178192\n",
      "Cyclic Loss:  0.2988104820251465\n",
      "Elapsed Time:  1575.341585111618\n",
      "Epoch: 5\n",
      "Batch:  0\n",
      "Task Loss:  0.2533304989337921\n",
      "Reconstruction Loss:  0.10903581976890564\n",
      "Cyclic Loss:  0.5581241250038147\n",
      "Batch:  300\n",
      "Task Loss:  0.26907819509506226\n",
      "Reconstruction Loss:  0.08352721482515335\n",
      "Cyclic Loss:  0.34064820408821106\n",
      "Batch:  600\n",
      "Task Loss:  0.2604994773864746\n",
      "Reconstruction Loss:  0.10409679263830185\n",
      "Cyclic Loss:  0.2781238555908203\n",
      "Batch:  900\n",
      "Task Loss:  0.24537846446037292\n",
      "Reconstruction Loss:  0.0859021544456482\n",
      "Cyclic Loss:  0.2784212827682495\n",
      "Batch:  1200\n",
      "Task Loss:  0.29180628061294556\n",
      "Reconstruction Loss:  0.0896877646446228\n",
      "Cyclic Loss:  0.4060460031032562\n",
      "Batch:  1500\n",
      "Task Loss:  0.26940053701400757\n",
      "Reconstruction Loss:  0.10357245802879333\n",
      "Cyclic Loss:  0.42689424753189087\n",
      "Elapsed Time:  1578.04711886247\n",
      "Epoch: 6\n",
      "Batch:  0\n",
      "Task Loss:  0.2547900080680847\n",
      "Reconstruction Loss:  0.08693521469831467\n",
      "Cyclic Loss:  0.3013344407081604\n",
      "Batch:  300\n",
      "Task Loss:  0.31309032440185547\n",
      "Reconstruction Loss:  0.08387365192174911\n",
      "Cyclic Loss:  0.3281097114086151\n",
      "Batch:  600\n",
      "Task Loss:  0.2989406883716583\n",
      "Reconstruction Loss:  0.1066598892211914\n",
      "Cyclic Loss:  0.4234801232814789\n",
      "Batch:  900\n",
      "Task Loss:  0.31490445137023926\n",
      "Reconstruction Loss:  0.08155510574579239\n",
      "Cyclic Loss:  0.28526005148887634\n",
      "Batch:  1200\n",
      "Task Loss:  0.25138694047927856\n",
      "Reconstruction Loss:  0.08548209071159363\n",
      "Cyclic Loss:  0.30265942215919495\n",
      "Batch:  1500\n",
      "Task Loss:  0.27096474170684814\n",
      "Reconstruction Loss:  0.09916459769010544\n",
      "Cyclic Loss:  0.4114244878292084\n",
      "Elapsed Time:  1576.4791998182025\n",
      "Epoch: 7\n",
      "Batch:  0\n",
      "Task Loss:  0.27287623286247253\n",
      "Reconstruction Loss:  0.10037808120250702\n",
      "Cyclic Loss:  0.4009259045124054\n",
      "Batch:  300\n",
      "Task Loss:  0.2510908544063568\n",
      "Reconstruction Loss:  0.09709589183330536\n",
      "Cyclic Loss:  0.40709036588668823\n",
      "Batch:  600\n",
      "Task Loss:  0.19621002674102783\n",
      "Reconstruction Loss:  0.10703279823064804\n",
      "Cyclic Loss:  0.3601485788822174\n",
      "Batch:  900\n",
      "Task Loss:  0.2809951603412628\n",
      "Reconstruction Loss:  0.09336381405591965\n",
      "Cyclic Loss:  0.4100351929664612\n",
      "Batch:  1200\n",
      "Task Loss:  0.22097228467464447\n",
      "Reconstruction Loss:  0.09617336839437485\n",
      "Cyclic Loss:  0.3553208112716675\n",
      "Batch:  1500\n",
      "Task Loss:  0.2378058284521103\n",
      "Reconstruction Loss:  0.09232481569051743\n",
      "Cyclic Loss:  0.3386535048484802\n",
      "Elapsed Time:  1575.6111213564873\n",
      "Epoch: 8\n",
      "Batch:  0\n",
      "Task Loss:  0.28810277581214905\n",
      "Reconstruction Loss:  0.09333808720111847\n",
      "Cyclic Loss:  0.4269362986087799\n",
      "Batch:  300\n",
      "Task Loss:  0.2675704061985016\n",
      "Reconstruction Loss:  0.08417532593011856\n",
      "Cyclic Loss:  0.3240911066532135\n",
      "Batch:  600\n",
      "Task Loss:  0.251505970954895\n",
      "Reconstruction Loss:  0.08453690260648727\n",
      "Cyclic Loss:  0.2657924294471741\n",
      "Batch:  900\n",
      "Task Loss:  0.24931037425994873\n",
      "Reconstruction Loss:  0.0885128304362297\n",
      "Cyclic Loss:  0.35901373624801636\n",
      "Batch:  1200\n",
      "Task Loss:  0.28619712591171265\n",
      "Reconstruction Loss:  0.08307049423456192\n",
      "Cyclic Loss:  0.331760436296463\n",
      "Batch:  1500\n",
      "Task Loss:  0.2846151888370514\n",
      "Reconstruction Loss:  0.0971960574388504\n",
      "Cyclic Loss:  0.3544314205646515\n",
      "Elapsed Time:  1575.5499287976158\n",
      "Epoch: 9\n",
      "Batch:  0\n",
      "Task Loss:  0.24478107690811157\n",
      "Reconstruction Loss:  0.0859985500574112\n",
      "Cyclic Loss:  0.281216025352478\n",
      "Batch:  300\n",
      "Task Loss:  0.28967034816741943\n",
      "Reconstruction Loss:  0.0865798145532608\n",
      "Cyclic Loss:  0.3882908821105957\n",
      "Batch:  600\n",
      "Task Loss:  0.2621324956417084\n",
      "Reconstruction Loss:  0.08199954032897949\n",
      "Cyclic Loss:  0.2643093168735504\n",
      "Batch:  900\n",
      "Task Loss:  0.28241127729415894\n",
      "Reconstruction Loss:  0.08762335032224655\n",
      "Cyclic Loss:  0.3216143250465393\n",
      "Batch:  1200\n",
      "Task Loss:  0.2930676341056824\n",
      "Reconstruction Loss:  0.08129880577325821\n",
      "Cyclic Loss:  0.33612722158432007\n",
      "Batch:  1500\n",
      "Task Loss:  0.3478158712387085\n",
      "Reconstruction Loss:  0.09265827387571335\n",
      "Cyclic Loss:  0.46754369139671326\n",
      "Elapsed Time:  1575.9818890333177\n",
      "Epoch: 10\n",
      "Batch:  0\n",
      "Task Loss:  0.2396884262561798\n",
      "Reconstruction Loss:  0.08183678984642029\n",
      "Cyclic Loss:  0.2823222875595093\n",
      "Batch:  300\n",
      "Task Loss:  0.2550230026245117\n",
      "Reconstruction Loss:  0.08188093453645706\n",
      "Cyclic Loss:  0.30039548873901367\n",
      "Batch:  600\n",
      "Task Loss:  0.2720339000225067\n",
      "Reconstruction Loss:  0.08852209150791168\n",
      "Cyclic Loss:  0.32509762048721313\n",
      "Batch:  900\n",
      "Task Loss:  0.30729734897613525\n",
      "Reconstruction Loss:  0.08381429314613342\n",
      "Cyclic Loss:  0.3531390130519867\n",
      "Batch:  1200\n",
      "Task Loss:  0.27110278606414795\n",
      "Reconstruction Loss:  0.09253504872322083\n",
      "Cyclic Loss:  0.44807755947113037\n",
      "Batch:  1500\n",
      "Task Loss:  0.2843848764896393\n",
      "Reconstruction Loss:  0.0871039554476738\n",
      "Cyclic Loss:  0.2923243045806885\n",
      "Elapsed Time:  1575.3440902883356\n",
      "Epoch: 11\n",
      "Batch:  0\n",
      "Task Loss:  0.2660485804080963\n",
      "Reconstruction Loss:  0.08489134162664413\n",
      "Cyclic Loss:  0.27840301394462585\n",
      "Batch:  300\n",
      "Task Loss:  0.35284295678138733\n",
      "Reconstruction Loss:  0.12846198678016663\n",
      "Cyclic Loss:  0.7858054041862488\n",
      "Batch:  600\n",
      "Task Loss:  0.2571754455566406\n",
      "Reconstruction Loss:  0.08375462889671326\n",
      "Cyclic Loss:  0.2798757255077362\n",
      "Batch:  900\n",
      "Task Loss:  0.28231415152549744\n",
      "Reconstruction Loss:  0.08510740101337433\n",
      "Cyclic Loss:  0.29872754216194153\n",
      "Batch:  1200\n",
      "Task Loss:  0.21092252433300018\n",
      "Reconstruction Loss:  0.08754455298185349\n",
      "Cyclic Loss:  0.26843541860580444\n",
      "Batch:  1500\n",
      "Task Loss:  0.23739424347877502\n",
      "Reconstruction Loss:  0.08380022644996643\n",
      "Cyclic Loss:  0.2652801275253296\n",
      "Elapsed Time:  1574.8206182916958\n",
      "Epoch: 12\n",
      "Batch:  0\n",
      "Task Loss:  0.26371029019355774\n",
      "Reconstruction Loss:  0.09164940565824509\n",
      "Cyclic Loss:  0.3378591537475586\n",
      "Batch:  300\n",
      "Task Loss:  0.26685795187950134\n",
      "Reconstruction Loss:  0.09978143125772476\n",
      "Cyclic Loss:  0.4374581575393677\n",
      "Batch:  600\n",
      "Task Loss:  0.23659902811050415\n",
      "Reconstruction Loss:  0.08913964778184891\n",
      "Cyclic Loss:  0.3067419230937958\n",
      "Batch:  900\n",
      "Task Loss:  0.27175745368003845\n",
      "Reconstruction Loss:  0.08615254610776901\n",
      "Cyclic Loss:  0.300476998090744\n",
      "Batch:  1200\n",
      "Task Loss:  0.34127306938171387\n",
      "Reconstruction Loss:  0.25018373131752014\n",
      "Cyclic Loss:  0.7729863524436951\n",
      "Batch:  1500\n",
      "Task Loss:  0.22821581363677979\n",
      "Reconstruction Loss:  0.08068519830703735\n",
      "Cyclic Loss:  0.27962636947631836\n",
      "Elapsed Time:  1575.7571271382844\n",
      "Epoch: 13\n",
      "Batch:  0\n",
      "Task Loss:  0.2221604883670807\n",
      "Reconstruction Loss:  0.08451702445745468\n",
      "Cyclic Loss:  0.26976272463798523\n",
      "Batch:  300\n",
      "Task Loss:  0.2893393039703369\n",
      "Reconstruction Loss:  0.09310988336801529\n",
      "Cyclic Loss:  0.3468439280986786\n",
      "Batch:  600\n",
      "Task Loss:  0.2976187467575073\n",
      "Reconstruction Loss:  0.12290828675031662\n",
      "Cyclic Loss:  0.7027063369750977\n",
      "Batch:  900\n",
      "Task Loss:  0.2777111530303955\n",
      "Reconstruction Loss:  0.08126981556415558\n",
      "Cyclic Loss:  0.30965670943260193\n",
      "Batch:  1200\n",
      "Task Loss:  0.27204829454421997\n",
      "Reconstruction Loss:  0.10035216808319092\n",
      "Cyclic Loss:  0.49542924761772156\n",
      "Batch:  1500\n",
      "Task Loss:  0.3413058817386627\n",
      "Reconstruction Loss:  0.08647909015417099\n",
      "Cyclic Loss:  0.40226197242736816\n",
      "Elapsed Time:  1575.9091711725507\n",
      "Epoch: 14\n",
      "Batch:  0\n",
      "Task Loss:  0.3367842733860016\n",
      "Reconstruction Loss:  0.09502465277910233\n",
      "Cyclic Loss:  0.4630599319934845\n",
      "Batch:  300\n",
      "Task Loss:  0.23684130609035492\n",
      "Reconstruction Loss:  0.08596321195363998\n",
      "Cyclic Loss:  0.27228039503097534\n",
      "Batch:  600\n",
      "Task Loss:  0.30743134021759033\n",
      "Reconstruction Loss:  0.08672424405813217\n",
      "Cyclic Loss:  0.36206942796707153\n",
      "Batch:  900\n",
      "Task Loss:  0.24128329753875732\n",
      "Reconstruction Loss:  0.08361665904521942\n",
      "Cyclic Loss:  0.2638618052005768\n",
      "Batch:  1200\n",
      "Task Loss:  0.2590855062007904\n",
      "Reconstruction Loss:  0.08404222875833511\n",
      "Cyclic Loss:  0.2968539595603943\n",
      "Batch:  1500\n",
      "Task Loss:  0.2322750687599182\n",
      "Reconstruction Loss:  0.08546729385852814\n",
      "Cyclic Loss:  0.27874886989593506\n",
      "Elapsed Time:  1575.7780847708384\n",
      "Epoch: 15\n",
      "Batch:  0\n",
      "Task Loss:  0.2816847264766693\n",
      "Reconstruction Loss:  0.09345906972885132\n",
      "Cyclic Loss:  0.32703912258148193\n",
      "Batch:  300\n",
      "Task Loss:  0.2721431255340576\n",
      "Reconstruction Loss:  0.09474662691354752\n",
      "Cyclic Loss:  0.3812416195869446\n",
      "Batch:  600\n",
      "Task Loss:  0.23945499956607819\n",
      "Reconstruction Loss:  0.08062715083360672\n",
      "Cyclic Loss:  0.27597030997276306\n",
      "Batch:  900\n",
      "Task Loss:  0.27930381894111633\n",
      "Reconstruction Loss:  0.08240467309951782\n",
      "Cyclic Loss:  0.2882349491119385\n",
      "Batch:  1200\n",
      "Task Loss:  0.2230754792690277\n",
      "Reconstruction Loss:  0.08631667494773865\n",
      "Cyclic Loss:  0.2822865843772888\n",
      "Batch:  1500\n",
      "Task Loss:  0.26269978284835815\n",
      "Reconstruction Loss:  0.0808497816324234\n",
      "Cyclic Loss:  0.30640333890914917\n",
      "Elapsed Time:  1575.8472322970629\n",
      "Epoch: 16\n",
      "Batch:  0\n",
      "Task Loss:  0.2782377600669861\n",
      "Reconstruction Loss:  0.08532258868217468\n",
      "Cyclic Loss:  0.3587803840637207\n",
      "Batch:  300\n",
      "Task Loss:  0.27640217542648315\n",
      "Reconstruction Loss:  0.08269120007753372\n",
      "Cyclic Loss:  0.3385137915611267\n",
      "Batch:  600\n",
      "Task Loss:  0.2526191473007202\n",
      "Reconstruction Loss:  0.13372200727462769\n",
      "Cyclic Loss:  0.6196611523628235\n",
      "Batch:  900\n",
      "Task Loss:  0.22824323177337646\n",
      "Reconstruction Loss:  0.08203662931919098\n",
      "Cyclic Loss:  0.2441723495721817\n",
      "Batch:  1200\n",
      "Task Loss:  0.21642336249351501\n",
      "Reconstruction Loss:  0.092130646109581\n",
      "Cyclic Loss:  0.29957956075668335\n",
      "Batch:  1500\n",
      "Task Loss:  0.31006166338920593\n",
      "Reconstruction Loss:  0.10477069765329361\n",
      "Cyclic Loss:  0.46957242488861084\n",
      "Elapsed Time:  1575.7898387067457\n",
      "Epoch: 17\n",
      "Batch:  0\n",
      "Task Loss:  0.25938916206359863\n",
      "Reconstruction Loss:  0.08494575321674347\n",
      "Cyclic Loss:  0.2881632149219513\n",
      "Batch:  300\n",
      "Task Loss:  0.2685384750366211\n",
      "Reconstruction Loss:  0.08106422424316406\n",
      "Cyclic Loss:  0.2805120050907135\n",
      "Batch:  600\n",
      "Task Loss:  0.25599342584609985\n",
      "Reconstruction Loss:  0.11235850304365158\n",
      "Cyclic Loss:  0.4827459752559662\n",
      "Batch:  900\n",
      "Task Loss:  0.22104573249816895\n",
      "Reconstruction Loss:  0.08468605577945709\n",
      "Cyclic Loss:  0.23116810619831085\n",
      "Batch:  1200\n",
      "Task Loss:  0.2522980272769928\n",
      "Reconstruction Loss:  0.08486250787973404\n",
      "Cyclic Loss:  0.2921048402786255\n",
      "Batch:  1500\n",
      "Task Loss:  0.21791547536849976\n",
      "Reconstruction Loss:  0.0977480337023735\n",
      "Cyclic Loss:  0.44776344299316406\n",
      "Elapsed Time:  1576.0078430175781\n",
      "Epoch: 18\n",
      "Batch:  0\n",
      "Task Loss:  0.3097069263458252\n",
      "Reconstruction Loss:  0.08266300708055496\n",
      "Cyclic Loss:  0.40089040994644165\n",
      "Batch:  300\n",
      "Task Loss:  0.23755429685115814\n",
      "Reconstruction Loss:  0.08158823847770691\n",
      "Cyclic Loss:  0.2683970034122467\n",
      "Batch:  600\n",
      "Task Loss:  0.257686972618103\n",
      "Reconstruction Loss:  0.08871902525424957\n",
      "Cyclic Loss:  0.25189027190208435\n",
      "Batch:  900\n",
      "Task Loss:  0.2720121443271637\n",
      "Reconstruction Loss:  0.08331090956926346\n",
      "Cyclic Loss:  0.27802181243896484\n",
      "Batch:  1200\n",
      "Task Loss:  0.27136844396591187\n",
      "Reconstruction Loss:  0.0815795287489891\n",
      "Cyclic Loss:  0.32364779710769653\n",
      "Batch:  1500\n",
      "Task Loss:  0.2718968391418457\n",
      "Reconstruction Loss:  0.08230409026145935\n",
      "Cyclic Loss:  0.30833950638771057\n",
      "Elapsed Time:  1576.7711526971113\n",
      "Epoch: 19\n",
      "Batch:  0\n",
      "Task Loss:  0.25430187582969666\n",
      "Reconstruction Loss:  0.10140839964151382\n",
      "Cyclic Loss:  0.4200877845287323\n",
      "Batch:  300\n",
      "Task Loss:  0.27948662638664246\n",
      "Reconstruction Loss:  0.08285142481327057\n",
      "Cyclic Loss:  0.2938142716884613\n",
      "Batch:  600\n",
      "Task Loss:  0.2717478275299072\n",
      "Reconstruction Loss:  0.08361998945474625\n",
      "Cyclic Loss:  0.30935609340667725\n",
      "Batch:  900\n",
      "Task Loss:  0.33089977502822876\n",
      "Reconstruction Loss:  0.13579678535461426\n",
      "Cyclic Loss:  0.38029104471206665\n",
      "Batch:  1200\n",
      "Task Loss:  0.30230623483657837\n",
      "Reconstruction Loss:  0.08215353637933731\n",
      "Cyclic Loss:  0.3579576015472412\n",
      "Batch:  1500\n",
      "Task Loss:  0.29801687598228455\n",
      "Reconstruction Loss:  0.08355394750833511\n",
      "Cyclic Loss:  0.3627307713031769\n",
      "Elapsed Time:  1576.8239812374115\n",
      "Epoch: 20\n",
      "Batch:  0\n",
      "Task Loss:  0.3525660037994385\n",
      "Reconstruction Loss:  0.08026827126741409\n",
      "Cyclic Loss:  0.38517674803733826\n",
      "Batch:  300\n",
      "Task Loss:  0.2571331560611725\n",
      "Reconstruction Loss:  0.08058038353919983\n",
      "Cyclic Loss:  0.2756195366382599\n",
      "Batch:  600\n",
      "Task Loss:  0.2542687952518463\n",
      "Reconstruction Loss:  0.10025104880332947\n",
      "Cyclic Loss:  0.3804459273815155\n",
      "Batch:  900\n",
      "Task Loss:  0.2646714448928833\n",
      "Reconstruction Loss:  0.08860403299331665\n",
      "Cyclic Loss:  0.3278971314430237\n",
      "Batch:  1200\n",
      "Task Loss:  0.2594393789768219\n",
      "Reconstruction Loss:  0.08483466506004333\n",
      "Cyclic Loss:  0.32251331210136414\n",
      "Batch:  1500\n",
      "Task Loss:  0.2802216112613678\n",
      "Reconstruction Loss:  0.1031966432929039\n",
      "Cyclic Loss:  0.24966467916965485\n",
      "Elapsed Time:  1576.1495861780077\n",
      "Epoch: 21\n",
      "Batch:  0\n",
      "Task Loss:  0.3096317946910858\n",
      "Reconstruction Loss:  0.1234234943985939\n",
      "Cyclic Loss:  0.33982017636299133\n",
      "Batch:  300\n",
      "Task Loss:  0.2589585781097412\n",
      "Reconstruction Loss:  0.0839521735906601\n",
      "Cyclic Loss:  0.285839319229126\n",
      "Batch:  600\n",
      "Task Loss:  0.26112303137779236\n",
      "Reconstruction Loss:  0.08179294317960739\n",
      "Cyclic Loss:  0.2670802175998688\n",
      "Batch:  900\n",
      "Task Loss:  0.24338844418525696\n",
      "Reconstruction Loss:  0.09938228130340576\n",
      "Cyclic Loss:  0.41068536043167114\n",
      "Batch:  1200\n",
      "Task Loss:  0.3446720242500305\n",
      "Reconstruction Loss:  0.07897648215293884\n",
      "Cyclic Loss:  0.3905525803565979\n",
      "Batch:  1500\n",
      "Task Loss:  0.35296565294265747\n",
      "Reconstruction Loss:  0.0998011976480484\n",
      "Cyclic Loss:  0.5516841411590576\n",
      "Elapsed Time:  1575.784407214685\n",
      "Epoch: 22\n",
      "Batch:  0\n",
      "Task Loss:  0.2661552429199219\n",
      "Reconstruction Loss:  0.08822353184223175\n",
      "Cyclic Loss:  0.2670450508594513\n",
      "Batch:  300\n",
      "Task Loss:  0.22836096584796906\n",
      "Reconstruction Loss:  0.0895165205001831\n",
      "Cyclic Loss:  0.3049054741859436\n",
      "Batch:  600\n",
      "Task Loss:  0.24084284901618958\n",
      "Reconstruction Loss:  0.0838385745882988\n",
      "Cyclic Loss:  0.30239927768707275\n",
      "Batch:  900\n",
      "Task Loss:  0.270574152469635\n",
      "Reconstruction Loss:  0.09083904325962067\n",
      "Cyclic Loss:  0.2850857377052307\n",
      "Batch:  1200\n",
      "Task Loss:  0.2987600564956665\n",
      "Reconstruction Loss:  0.11565215140581131\n",
      "Cyclic Loss:  0.546825110912323\n",
      "Batch:  1500\n",
      "Task Loss:  0.27372944355010986\n",
      "Reconstruction Loss:  0.0960693284869194\n",
      "Cyclic Loss:  0.31711331009864807\n",
      "Elapsed Time:  1575.6862565641818\n",
      "Epoch: 23\n",
      "Batch:  0\n",
      "Task Loss:  0.260077565908432\n",
      "Reconstruction Loss:  0.08720554411411285\n",
      "Cyclic Loss:  0.2992536425590515\n",
      "Batch:  300\n",
      "Task Loss:  0.23388642072677612\n",
      "Reconstruction Loss:  0.09872101247310638\n",
      "Cyclic Loss:  0.4087015986442566\n",
      "Batch:  600\n",
      "Task Loss:  0.3230668902397156\n",
      "Reconstruction Loss:  0.08031716197729111\n",
      "Cyclic Loss:  0.3525899350643158\n",
      "Batch:  900\n",
      "Task Loss:  0.24043774604797363\n",
      "Reconstruction Loss:  0.09303496778011322\n",
      "Cyclic Loss:  0.40831080079078674\n",
      "Batch:  1200\n",
      "Task Loss:  0.27829432487487793\n",
      "Reconstruction Loss:  0.08425496518611908\n",
      "Cyclic Loss:  0.33422526717185974\n",
      "Batch:  1500\n",
      "Task Loss:  0.23172351717948914\n",
      "Reconstruction Loss:  0.08769119530916214\n",
      "Cyclic Loss:  0.2806844413280487\n",
      "Elapsed Time:  1575.3331062893074\n",
      "Epoch: 24\n",
      "Batch:  0\n",
      "Task Loss:  0.27100542187690735\n",
      "Reconstruction Loss:  0.0869871973991394\n",
      "Cyclic Loss:  0.2980198860168457\n",
      "Batch:  300\n",
      "Task Loss:  0.2836316227912903\n",
      "Reconstruction Loss:  0.08663209527730942\n",
      "Cyclic Loss:  0.3222682774066925\n",
      "Batch:  600\n",
      "Task Loss:  0.29582515358924866\n",
      "Reconstruction Loss:  0.09564033895730972\n",
      "Cyclic Loss:  0.37550610303878784\n",
      "Batch:  900\n",
      "Task Loss:  0.25375521183013916\n",
      "Reconstruction Loss:  0.0874742940068245\n",
      "Cyclic Loss:  0.39372050762176514\n",
      "Batch:  1200\n",
      "Task Loss:  0.26342788338661194\n",
      "Reconstruction Loss:  0.08153501898050308\n",
      "Cyclic Loss:  0.269479900598526\n",
      "Batch:  1500\n",
      "Task Loss:  0.2896273136138916\n",
      "Reconstruction Loss:  0.08409209549427032\n",
      "Cyclic Loss:  0.2760956287384033\n",
      "Elapsed Time:  1574.6566074180603\n",
      "Epoch: 25\n",
      "Batch:  0\n",
      "Task Loss:  0.24141696095466614\n",
      "Reconstruction Loss:  0.11727184057235718\n",
      "Cyclic Loss:  0.49243849515914917\n",
      "Batch:  300\n",
      "Task Loss:  0.26735368371009827\n",
      "Reconstruction Loss:  0.08761164546012878\n",
      "Cyclic Loss:  0.36352312564849854\n",
      "Batch:  600\n",
      "Task Loss:  0.3203340768814087\n",
      "Reconstruction Loss:  0.08627081662416458\n",
      "Cyclic Loss:  0.40770262479782104\n",
      "Batch:  900\n",
      "Task Loss:  0.277726411819458\n",
      "Reconstruction Loss:  0.08684108406305313\n",
      "Cyclic Loss:  0.2904554009437561\n",
      "Batch:  1200\n",
      "Task Loss:  0.34651026129722595\n",
      "Reconstruction Loss:  0.09616237133741379\n",
      "Cyclic Loss:  0.4421621859073639\n",
      "Batch:  1500\n",
      "Task Loss:  0.26798656582832336\n",
      "Reconstruction Loss:  0.0952879935503006\n",
      "Cyclic Loss:  0.4495367407798767\n",
      "Elapsed Time:  1574.2020559219213\n",
      "Epoch: 26\n",
      "Batch:  0\n",
      "Task Loss:  0.24291732907295227\n",
      "Reconstruction Loss:  0.08508957922458649\n",
      "Cyclic Loss:  0.29190897941589355\n",
      "Batch:  300\n",
      "Task Loss:  0.27943941950798035\n",
      "Reconstruction Loss:  0.08966372907161713\n",
      "Cyclic Loss:  0.3269311785697937\n",
      "Batch:  600\n",
      "Task Loss:  0.2289399951696396\n",
      "Reconstruction Loss:  0.08857294917106628\n",
      "Cyclic Loss:  0.30272844433784485\n",
      "Batch:  900\n",
      "Task Loss:  0.2730516195297241\n",
      "Reconstruction Loss:  0.0821990966796875\n",
      "Cyclic Loss:  0.3063357472419739\n",
      "Batch:  1200\n",
      "Task Loss:  0.23846733570098877\n",
      "Reconstruction Loss:  0.08362366259098053\n",
      "Cyclic Loss:  0.2771068513393402\n",
      "Batch:  1500\n",
      "Task Loss:  0.32011348009109497\n",
      "Reconstruction Loss:  0.08934012055397034\n",
      "Cyclic Loss:  0.3953050971031189\n",
      "Elapsed Time:  1574.593706952201\n",
      "Epoch: 27\n",
      "Batch:  0\n",
      "Task Loss:  0.3030860424041748\n",
      "Reconstruction Loss:  0.08276837319135666\n",
      "Cyclic Loss:  0.31296926736831665\n",
      "Batch:  300\n",
      "Task Loss:  0.23673754930496216\n",
      "Reconstruction Loss:  0.09857647866010666\n",
      "Cyclic Loss:  0.4356597661972046\n",
      "Batch:  600\n",
      "Task Loss:  0.2944435477256775\n",
      "Reconstruction Loss:  0.0802907645702362\n",
      "Cyclic Loss:  0.3253633975982666\n",
      "Batch:  900\n",
      "Task Loss:  0.3078185021877289\n",
      "Reconstruction Loss:  0.08664266020059586\n",
      "Cyclic Loss:  0.3887861669063568\n",
      "Batch:  1200\n",
      "Task Loss:  0.2820275127887726\n",
      "Reconstruction Loss:  0.08535957336425781\n",
      "Cyclic Loss:  0.31380078196525574\n",
      "Batch:  1500\n",
      "Task Loss:  0.21314996480941772\n",
      "Reconstruction Loss:  0.11076880246400833\n",
      "Cyclic Loss:  0.4001937210559845\n",
      "Elapsed Time:  1574.169051851545\n",
      "Epoch: 28\n",
      "Batch:  0\n",
      "Task Loss:  0.24677756428718567\n",
      "Reconstruction Loss:  0.08804420381784439\n",
      "Cyclic Loss:  0.3445951044559479\n",
      "Batch:  300\n",
      "Task Loss:  0.26015567779541016\n",
      "Reconstruction Loss:  0.08888215571641922\n",
      "Cyclic Loss:  0.3070812225341797\n",
      "Batch:  600\n",
      "Task Loss:  0.28308749198913574\n",
      "Reconstruction Loss:  0.09527057409286499\n",
      "Cyclic Loss:  0.40982332825660706\n",
      "Batch:  900\n",
      "Task Loss:  0.20411479473114014\n",
      "Reconstruction Loss:  0.08175300806760788\n",
      "Cyclic Loss:  0.23469382524490356\n",
      "Batch:  1200\n",
      "Task Loss:  0.2793118953704834\n",
      "Reconstruction Loss:  0.08753150701522827\n",
      "Cyclic Loss:  0.4122077226638794\n",
      "Batch:  1500\n",
      "Task Loss:  0.21824049949645996\n",
      "Reconstruction Loss:  0.09370654821395874\n",
      "Cyclic Loss:  0.36101996898651123\n",
      "Elapsed Time:  1574.1036990511006\n",
      "Epoch: 29\n",
      "Batch:  0\n",
      "Task Loss:  0.2241288125514984\n",
      "Reconstruction Loss:  0.08239099383354187\n",
      "Cyclic Loss:  0.29710933566093445\n",
      "Batch:  300\n",
      "Task Loss:  0.29469597339630127\n",
      "Reconstruction Loss:  0.10219050198793411\n",
      "Cyclic Loss:  0.2888445556163788\n",
      "Batch:  600\n",
      "Task Loss:  0.22075454890727997\n",
      "Reconstruction Loss:  0.08205759525299072\n",
      "Cyclic Loss:  0.2510407865047455\n",
      "Batch:  900\n",
      "Task Loss:  0.22568565607070923\n",
      "Reconstruction Loss:  0.08651150017976761\n",
      "Cyclic Loss:  0.2490156590938568\n",
      "Batch:  1200\n",
      "Task Loss:  0.32486236095428467\n",
      "Reconstruction Loss:  0.09370038658380508\n",
      "Cyclic Loss:  0.3758862316608429\n",
      "Batch:  1500\n",
      "Task Loss:  0.2510119378566742\n",
      "Reconstruction Loss:  0.08679565787315369\n",
      "Cyclic Loss:  0.2946951389312744\n",
      "Elapsed Time:  1573.379077498118\n",
      "Epoch: 30\n",
      "Batch:  0\n",
      "Task Loss:  0.3127492368221283\n",
      "Reconstruction Loss:  0.101705402135849\n",
      "Cyclic Loss:  0.5581213235855103\n",
      "Batch:  300\n",
      "Task Loss:  0.27610155940055847\n",
      "Reconstruction Loss:  0.08254389464855194\n",
      "Cyclic Loss:  0.2964785695075989\n",
      "Batch:  600\n",
      "Task Loss:  0.2883598804473877\n",
      "Reconstruction Loss:  0.08374711126089096\n",
      "Cyclic Loss:  0.3244129419326782\n",
      "Batch:  900\n",
      "Task Loss:  0.3127516508102417\n",
      "Reconstruction Loss:  0.0898948460817337\n",
      "Cyclic Loss:  0.3825538456439972\n",
      "Batch:  1200\n",
      "Task Loss:  0.24646802246570587\n",
      "Reconstruction Loss:  0.09352072328329086\n",
      "Cyclic Loss:  0.39474961161613464\n",
      "Batch:  1500\n",
      "Task Loss:  0.2631891965866089\n",
      "Reconstruction Loss:  0.09123478829860687\n",
      "Cyclic Loss:  0.3352278769016266\n",
      "Elapsed Time:  1572.7317435049242\n",
      "Epoch: 31\n",
      "Batch:  0\n",
      "Task Loss:  0.2583788335323334\n",
      "Reconstruction Loss:  0.0836179181933403\n",
      "Cyclic Loss:  0.3289056718349457\n",
      "Batch:  300\n",
      "Task Loss:  0.2576826214790344\n",
      "Reconstruction Loss:  0.08083391934633255\n",
      "Cyclic Loss:  0.25550368428230286\n",
      "Batch:  600\n",
      "Task Loss:  0.27150580286979675\n",
      "Reconstruction Loss:  0.08956850320100784\n",
      "Cyclic Loss:  0.31212788820266724\n",
      "Batch:  900\n",
      "Task Loss:  0.25459811091423035\n",
      "Reconstruction Loss:  0.09551195800304413\n",
      "Cyclic Loss:  0.31854209303855896\n",
      "Batch:  1200\n",
      "Task Loss:  0.22723501920700073\n",
      "Reconstruction Loss:  0.11646629869937897\n",
      "Cyclic Loss:  0.549533486366272\n",
      "Batch:  1500\n",
      "Task Loss:  0.2376820296049118\n",
      "Reconstruction Loss:  0.08109129965305328\n",
      "Cyclic Loss:  0.27303358912467957\n",
      "Elapsed Time:  1573.0903252884746\n",
      "Epoch: 32\n",
      "Batch:  0\n",
      "Task Loss:  0.3681012690067291\n",
      "Reconstruction Loss:  0.0842413529753685\n",
      "Cyclic Loss:  0.36576443910598755\n",
      "Batch:  300\n",
      "Task Loss:  0.353655070066452\n",
      "Reconstruction Loss:  0.09081878513097763\n",
      "Cyclic Loss:  0.43051546812057495\n",
      "Batch:  600\n",
      "Task Loss:  0.2116481065750122\n",
      "Reconstruction Loss:  0.08246877789497375\n",
      "Cyclic Loss:  0.2510431408882141\n",
      "Batch:  900\n",
      "Task Loss:  0.27641284465789795\n",
      "Reconstruction Loss:  0.08762520551681519\n",
      "Cyclic Loss:  0.30800214409828186\n",
      "Batch:  1200\n",
      "Task Loss:  0.23756609857082367\n",
      "Reconstruction Loss:  0.08972768485546112\n",
      "Cyclic Loss:  0.3535521924495697\n",
      "Batch:  1500\n",
      "Task Loss:  0.29985368251800537\n",
      "Reconstruction Loss:  0.11663490533828735\n",
      "Cyclic Loss:  0.5649076700210571\n",
      "Elapsed Time:  1573.5540453592937\n",
      "Epoch: 33\n",
      "Batch:  0\n",
      "Task Loss:  0.23900260031223297\n",
      "Reconstruction Loss:  0.08422660827636719\n",
      "Cyclic Loss:  0.2914223372936249\n",
      "Batch:  300\n",
      "Task Loss:  0.317985475063324\n",
      "Reconstruction Loss:  0.08543068170547485\n",
      "Cyclic Loss:  0.3100627064704895\n",
      "Batch:  600\n",
      "Task Loss:  0.4500988721847534\n",
      "Reconstruction Loss:  0.09074398875236511\n",
      "Cyclic Loss:  0.5169540047645569\n",
      "Batch:  900\n",
      "Task Loss:  0.3027515411376953\n",
      "Reconstruction Loss:  0.0858524814248085\n",
      "Cyclic Loss:  0.3211081922054291\n",
      "Batch:  1200\n",
      "Task Loss:  0.27085936069488525\n",
      "Reconstruction Loss:  0.08479215204715729\n",
      "Cyclic Loss:  0.2833315134048462\n",
      "Batch:  1500\n",
      "Task Loss:  0.3339071273803711\n",
      "Reconstruction Loss:  0.09910847246646881\n",
      "Cyclic Loss:  0.4784826636314392\n",
      "Elapsed Time:  1573.1915224229588\n",
      "Epoch: 34\n",
      "Batch:  0\n",
      "Task Loss:  0.3145765960216522\n",
      "Reconstruction Loss:  0.10165087878704071\n",
      "Cyclic Loss:  0.4722316861152649\n",
      "Batch:  300\n",
      "Task Loss:  0.252642959356308\n",
      "Reconstruction Loss:  0.09120643138885498\n",
      "Cyclic Loss:  0.38413676619529724\n",
      "Batch:  600\n",
      "Task Loss:  0.2968369722366333\n",
      "Reconstruction Loss:  0.08789054304361343\n",
      "Cyclic Loss:  0.29255545139312744\n",
      "Batch:  900\n",
      "Task Loss:  0.29507559537887573\n",
      "Reconstruction Loss:  0.08810429275035858\n",
      "Cyclic Loss:  0.3073906898498535\n",
      "Batch:  1200\n",
      "Task Loss:  0.29106801748275757\n",
      "Reconstruction Loss:  0.08232565224170685\n",
      "Cyclic Loss:  0.302634060382843\n",
      "Batch:  1500\n",
      "Task Loss:  0.2264576554298401\n",
      "Reconstruction Loss:  0.09690559655427933\n",
      "Cyclic Loss:  0.3798399865627289\n",
      "Elapsed Time:  1572.8452309199743\n",
      "Epoch: 35\n",
      "Batch:  0\n",
      "Task Loss:  0.2495936155319214\n",
      "Reconstruction Loss:  0.09297022223472595\n",
      "Cyclic Loss:  0.34436389803886414\n",
      "Batch:  300\n",
      "Task Loss:  0.21222051978111267\n",
      "Reconstruction Loss:  0.0845261812210083\n",
      "Cyclic Loss:  0.26155027747154236\n",
      "Batch:  600\n",
      "Task Loss:  0.2663002610206604\n",
      "Reconstruction Loss:  0.08560387045145035\n",
      "Cyclic Loss:  0.2876514196395874\n",
      "Batch:  900\n",
      "Task Loss:  0.3151048421859741\n",
      "Reconstruction Loss:  0.11279284954071045\n",
      "Cyclic Loss:  0.6182919144630432\n",
      "Batch:  1200\n",
      "Task Loss:  0.28996405005455017\n",
      "Reconstruction Loss:  0.08548880368471146\n",
      "Cyclic Loss:  0.3405255973339081\n",
      "Batch:  1500\n",
      "Task Loss:  0.2828904688358307\n",
      "Reconstruction Loss:  0.0898047611117363\n",
      "Cyclic Loss:  0.3652108609676361\n",
      "Elapsed Time:  1572.6169819103347\n",
      "Epoch: 36\n",
      "Batch:  0\n",
      "Task Loss:  0.2632322311401367\n",
      "Reconstruction Loss:  0.09332534670829773\n",
      "Cyclic Loss:  0.3851410448551178\n",
      "Batch:  300\n",
      "Task Loss:  0.27163293957710266\n",
      "Reconstruction Loss:  0.08030426502227783\n",
      "Cyclic Loss:  0.30077043175697327\n",
      "Batch:  600\n",
      "Task Loss:  0.2141318917274475\n",
      "Reconstruction Loss:  0.0938805565237999\n",
      "Cyclic Loss:  0.38118550181388855\n",
      "Batch:  900\n",
      "Task Loss:  0.27107957005500793\n",
      "Reconstruction Loss:  0.08301596343517303\n",
      "Cyclic Loss:  0.31428027153015137\n",
      "Batch:  1200\n",
      "Task Loss:  0.2552695870399475\n",
      "Reconstruction Loss:  0.08677521347999573\n",
      "Cyclic Loss:  0.28438612818717957\n",
      "Batch:  1500\n",
      "Task Loss:  0.23870185017585754\n",
      "Reconstruction Loss:  0.08756831288337708\n",
      "Cyclic Loss:  0.32072150707244873\n",
      "Elapsed Time:  1572.7718263187924\n",
      "Epoch: 37\n",
      "Batch:  0\n",
      "Task Loss:  0.23429878056049347\n",
      "Reconstruction Loss:  0.0792284607887268\n",
      "Cyclic Loss:  0.282488614320755\n",
      "Batch:  300\n",
      "Task Loss:  0.31984254717826843\n",
      "Reconstruction Loss:  0.09968686103820801\n",
      "Cyclic Loss:  0.4537906050682068\n",
      "Batch:  600\n",
      "Task Loss:  0.27411288022994995\n",
      "Reconstruction Loss:  0.08660981059074402\n",
      "Cyclic Loss:  0.35890552401542664\n",
      "Batch:  900\n",
      "Task Loss:  0.3224538564682007\n",
      "Reconstruction Loss:  0.0812992975115776\n",
      "Cyclic Loss:  0.3336283266544342\n",
      "Batch:  1200\n",
      "Task Loss:  0.3023485839366913\n",
      "Reconstruction Loss:  0.10469946265220642\n",
      "Cyclic Loss:  0.5910220146179199\n",
      "Batch:  1500\n",
      "Task Loss:  0.26629820466041565\n",
      "Reconstruction Loss:  0.08230365067720413\n",
      "Cyclic Loss:  0.2970134913921356\n",
      "Elapsed Time:  1572.6945881027925\n",
      "Epoch: 38\n",
      "Batch:  0\n",
      "Task Loss:  0.2231736183166504\n",
      "Reconstruction Loss:  0.08391155302524567\n",
      "Cyclic Loss:  0.2521367371082306\n",
      "Batch:  300\n",
      "Task Loss:  0.2516844868659973\n",
      "Reconstruction Loss:  0.10184995085000992\n",
      "Cyclic Loss:  0.2531137764453888\n",
      "Batch:  600\n",
      "Task Loss:  0.3224128782749176\n",
      "Reconstruction Loss:  0.08272641897201538\n",
      "Cyclic Loss:  0.3524158298969269\n",
      "Batch:  900\n",
      "Task Loss:  0.24966734647750854\n",
      "Reconstruction Loss:  0.08829557150602341\n",
      "Cyclic Loss:  0.24584728479385376\n",
      "Batch:  1200\n",
      "Task Loss:  0.2461767941713333\n",
      "Reconstruction Loss:  0.08379870653152466\n",
      "Cyclic Loss:  0.28618910908699036\n",
      "Batch:  1500\n",
      "Task Loss:  0.23858101665973663\n",
      "Reconstruction Loss:  0.0850272923707962\n",
      "Cyclic Loss:  0.29328516125679016\n",
      "Elapsed Time:  1572.5757904052734\n",
      "Epoch: 39\n",
      "Batch:  0\n",
      "Task Loss:  0.23966321349143982\n",
      "Reconstruction Loss:  0.08356494456529617\n",
      "Cyclic Loss:  0.3225446045398712\n",
      "Batch:  300\n",
      "Task Loss:  0.31685924530029297\n",
      "Reconstruction Loss:  0.08036432415246964\n",
      "Cyclic Loss:  0.3284403085708618\n",
      "Batch:  600\n",
      "Task Loss:  0.31615495681762695\n",
      "Reconstruction Loss:  0.12061254680156708\n",
      "Cyclic Loss:  0.68206387758255\n",
      "Batch:  900\n",
      "Task Loss:  0.26583540439605713\n",
      "Reconstruction Loss:  0.08481066673994064\n",
      "Cyclic Loss:  0.29548367857933044\n",
      "Batch:  1200\n",
      "Task Loss:  0.23073366284370422\n",
      "Reconstruction Loss:  0.08782146871089935\n",
      "Cyclic Loss:  0.2880465090274811\n",
      "Batch:  1500\n",
      "Task Loss:  0.23870296776294708\n",
      "Reconstruction Loss:  0.08930661529302597\n",
      "Cyclic Loss:  0.33710813522338867\n",
      "Elapsed Time:  1572.352025437355\n"
     ]
    }
   ],
   "source": [
    "loss_matrix=train(Encoder,phi,invphi,train_load,num_epochs=40)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
